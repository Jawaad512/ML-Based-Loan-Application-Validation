{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# LLM-BASED LOAN APPLICATION VALIDATION: CODE OVERVIEW"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This codebook lies at the heart of automating **loan application validation**. There are five main things that happen in this architecture.\n",
        "\n",
        "1. **Input:** You provide documents (PDF) and the applicant type (e.g. Service Holder).\n",
        "2. **Classification:** Each page is labeled by an AI model (e.g. “this page is NID”, “this is Bank Statement”).\n",
        "3. **Extraction:** For each document type, the model extracts key fields (names, numbers, amounts) into tables.\n",
        "4. **Validation:** Data from the Loan Application Form is cross-checked with the supporting documents (e.g. NID number on form vs NID document).\n",
        "5. **Output:** You get a validation table (Green / Yellow / Red / Missing) for a detailed deep dive, and an LLM-generated executive summary of the main insights."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "![alt text](img1-2.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Due to lack of public information, the dataset had to be generated synthetically. First, fake identities, information and numbers were generated, corresponding to different fields in documents. Then those identities were aggregated, and samples from those were used to backtest and stress-test the code. The sample documents were generated using HTML, respecting the original document layouts that are found in Bangladesh. The Loan Application Form was loosely modeled around the fields found in Jamuna Bank Loan Application Form.\n",
        "\n",
        "Each HTML file has an option to download the respective forms for each synthetic applicant.\n",
        "\n",
        "While backtesting, I hand-wrote the application forms to also stress-test the model's capability to read handwritten data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "![alt text](img2-1.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## System Requirements"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "A GPU with at least 16 GB VRAM is required to run this code. I have tried with lower parameter LLM models, but they yield lower quality outputs.\n",
        "\n",
        "Moreover, 8GB RAM is recommended and at least 20-25GB space is required to make room for the LLM.\n",
        "\n",
        "If your device does not meet this criteria, upload this document (and the input PDF) on Kaggle and use their cloud GPUs to run the code."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Initialization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "execution": {
          "iopub.execute_input": "2026-02-16T02:27:38.696501Z",
          "iopub.status.busy": "2026-02-16T02:27:38.696005Z",
          "iopub.status.idle": "2026-02-16T02:28:02.421224Z",
          "shell.execute_reply": "2026-02-16T02:28:02.420285Z",
          "shell.execute_reply.started": "2026-02-16T02:27:38.696474Z"
        },
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "'apt-get' is not recognized as an internal or external command,\n",
            "operable program or batch file.\n"
          ]
        }
      ],
      "source": [
        "# 1. INSTALLS (Kaggle cell)\n",
        "!apt-get update && apt-get install -y poppler-utils\n",
        "!pip install -q torch Pillow pandas git+https://github.com/huggingface/transformers qwen-vl-utils accelerate pdf2image bitsandbytes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**What this cell does:** Here we import the Python libraries we will use later: PyTorch (for running the AI model), image and PDF tools (PIL, pdf2image), the Qwen vision-language model and its processor, and pandas for tables. Think of this as loading the toolbox before we start working."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2026-02-16T02:28:02.423225Z",
          "iopub.status.busy": "2026-02-16T02:28:02.422914Z",
          "iopub.status.idle": "2026-02-16T02:28:02.427817Z",
          "shell.execute_reply": "2026-02-16T02:28:02.427024Z",
          "shell.execute_reply.started": "2026-02-16T02:28:02.423195Z"
        },
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import torch, gc\n",
        "from PIL import Image\n",
        "from pdf2image import convert_from_path\n",
        "from transformers import Qwen2_5_VLForConditionalGeneration, AutoProcessor, BitsAndBytesConfig\n",
        "from qwen_vl_utils import process_vision_info\n",
        "import re\n",
        "import pandas as pd\n",
        "from difflib import SequenceMatcher"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Loading the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The LLM used here is a **vision-language model** named Qwen. The initial idea was to work with OCR-based models (e.g. Paddle OCR VL), but LLMs like Qwen are pre-equipped with the capacity to understand language and contexts in a much sophisticated manner, reducing error probability. \n",
        "\n",
        "The Qwen model comes with visual receptor to process and understand both high-resolution images and text. It excels at tasks like fine-grained visual recognition, document parsing, and grounding, making it ideal for extracting structured data from complex documents like loan applications."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Here, the model is loaded with certain features and optimization:\n",
        "\n",
        "1. To ensure the model does not overcook existing GPU capacity, 4-bit-quantization was turned on. It compresses the model's weight precision from 32-bit floating points to 4-bit integer.\n",
        "2. We also load the “processor” that prepares images and text for the model. This step can take a few minutes the first time.\n",
        "3. torch_dtype=torch.bfloat16: Uses 16 bits per parameter instead of the standard 32 bits, reducing VRAM usage to half."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2026-02-16T02:28:02.429032Z",
          "iopub.status.busy": "2026-02-16T02:28:02.428702Z",
          "iopub.status.idle": "2026-02-16T02:28:48.048929Z",
          "shell.execute_reply": "2026-02-16T02:28:48.048183Z",
          "shell.execute_reply.started": "2026-02-16T02:28:02.428988Z"
        },
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading model...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3f7915d873504ab08fe237f69b60a062",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (incomplete total...): 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6c62665eb42a410b9aaf3d33935f8eda",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Fetching 5 files:   0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b9bfdcea8bb2405e96d27e306cce2889",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading weights:   0%|          | 0/729 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model and Processor loaded successfully!\n"
          ]
        }
      ],
      "source": [
        "# 2. QUANTIZED MODEL LOADING\n",
        "model_id = \"Qwen/Qwen2.5-VL-7B-Instruct\"\n",
        "\n",
        "# 4-bit config optimized for T4 GPUs (Kaggle)\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_use_double_quant=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_compute_dtype=torch.bfloat16 # Ensures computation happens in BF16\n",
        ")\n",
        "\n",
        "print(\"Loading model...\")\n",
        "\n",
        "# Added torch_dtype and revised the loading call\n",
        "model = Qwen2_5_VLForConditionalGeneration.from_pretrained(\n",
        "    model_id,\n",
        "    quantization_config=bnb_config,\n",
        "    device_map=\"auto\",\n",
        "    trust_remote_code=True,\n",
        "    torch_dtype=torch.bfloat16, # Vital for Qwen2.5-VL precision\n",
        ")\n",
        "\n",
        "processor = AutoProcessor.from_pretrained(model_id)\n",
        "print(\"Model and Processor loaded successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# STEP 1: CLASSIFICATION OF DOCUMENTS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To make life easier for bankers, the document classification was left to the LLM model.\n",
        "\n",
        "We define which document types the applicant must submit based on their “persona” (e.g. Service Holder, Self Employed, Businessman). For example, a Service Holder must provide NID, TIN, Loan Application Form, Utility Bill, Bank Statement, Pay Slip, and Employee ID. This list is used later to check if any required document is missing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2026-02-16T02:28:48.051486Z",
          "iopub.status.busy": "2026-02-16T02:28:48.050973Z",
          "iopub.status.idle": "2026-02-16T02:28:48.056220Z",
          "shell.execute_reply": "2026-02-16T02:28:48.055632Z",
          "shell.execute_reply.started": "2026-02-16T02:28:48.051451Z"
        },
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# PERSONA LOGIC\n",
        "def get_persona_categories(persona):\n",
        "    common = [\"NID\", \"TIN\", \"Loan Application Form\", \"Utility Bill\", \"Bank Statement\"]\n",
        "    mapping = {\n",
        "        \"Service Holder\": common + [\"Pay Slip\", \"Employee ID\"],\n",
        "        \"Self Employed\": common + [\"Professional Certificate\"],\n",
        "        \"Businessman\": common + [\"Trade License\"]\n",
        "    }\n",
        "    return mapping.get(persona, common + [\"Other\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This function takes a PDF and the applicant’s persona, converts each PDF page to an image, and sends all pages to the vision-language model. The model returns a label for each page (e.g. “Page 1: TIN”, “Page 2: Utility Bill”). So we get a list of (page number, document type) for the whole PDF.\n",
        "\n",
        "There are two strategic reasons for picking Scanned PDF as the input format:\n",
        "\n",
        "1. Most Bangladeshi professionals are incredibly comfortable with apps like CamScanner. It is a simple, easy tool to aggregate image-based documents.\n",
        "2. Top scanning-to-PDF apps automatically deskew the image and increase document readability. (Even if that weren't the case, there are Python libraries to improve photo clarity.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2026-02-16T02:28:48.057343Z",
          "iopub.status.busy": "2026-02-16T02:28:48.057095Z",
          "iopub.status.idle": "2026-02-16T02:28:48.075205Z",
          "shell.execute_reply": "2026-02-16T02:28:48.074431Z",
          "shell.execute_reply.started": "2026-02-16T02:28:48.057316Z"
        },
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def classify_doc_with_pages(pdf_path, persona):\n",
        "    images = convert_from_path(pdf_path)\n",
        "    categories = get_persona_categories(persona)\n",
        "    \n",
        "    # Indexed content list\n",
        "    content_list = []\n",
        "    for i, img in enumerate(images):\n",
        "        page_num = i + 1\n",
        "        content_list.append({\n",
        "            \"type\": \"image\",\n",
        "            \"image\": img,\n",
        "            \"max_pixels\": 512 * 512\n",
        "        })\n",
        "        # We add a text identifier for the model to \"see\" which image is which\n",
        "        content_list.append({\"type\": \"text\", \"text\": f\"This is Page {page_num}.\"})\n",
        "\n",
        "    # Targeted Prompt\n",
        "    prompt = (\n",
        "        \"Persona: {persona}. I have provided {len(images)} pages from a document. Your task is to classify each page into one of the following categories: [TIN, Utility Bill, Loan Application Form, Pay Slip, NID, Bank Statement]. Follow these specific classification rules: identify a TIN by 'Taxpayer's Identification Number' or 'TIN Certificate' ; a Utility Bill by 'Electricity Bill,' 'Power Development Board,' or similar utility terms ; a Loan Application Form by 'Loan Application Form' or sections like 'Employment Details' and 'Financial Information' ; a Pay Slip by 'PAYSLIP,' 'Earnings,' 'Deductions,' or 'Net Payable Amount' ; an NID by 'National ID Card' or 'জাতীয় পরিচয়পত্র' ; and a Bank Statement by 'Account Statement' or 'Statement of Accounts' containing a transaction table with 'Withdraw,' 'Deposit,' and 'Balance' columns. Format your response exactly as 'Page 1: [Category]' for every page and return ONLY the formatted list.\"\n",
        "    )\n",
        "    content_list.append({\"type\": \"text\", \"text\": prompt})\n",
        "\n",
        "    messages = [{\"role\": \"user\", \"content\": content_list}]\n",
        "\n",
        "    # Inference\n",
        "    text = processor.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
        "    image_inputs, _ = process_vision_info(messages)\n",
        "    inputs = processor(text=[text], images=image_inputs, padding=True, return_tensors=\"pt\").to(model.device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        output_ids = model.generate(**inputs, max_new_tokens=100) # Increased tokens for the list\n",
        "    generated_ids = [out[len(ins):] for ins, out in zip(inputs.input_ids, output_ids)]\n",
        "    raw_output = processor.batch_decode(generated_ids, skip_special_tokens=True)[0].strip()\n",
        "    \n",
        "    return raw_output, images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We run the classifier on a sample PDF of a synthetically generated applicant. \n",
        "\n",
        "If you are running the code on Kaggle, use the full path of the PDF in the coding environment.\n",
        "\n",
        "If you are running the code on Google Colab, just insert the PDF file name.\n",
        "\n",
        "If you are running the code locally, use the path of the PDF."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2026-02-16T02:28:48.077043Z",
          "iopub.status.busy": "2026-02-16T02:28:48.076221Z",
          "iopub.status.idle": "2026-02-16T02:29:26.971288Z",
          "shell.execute_reply": "2026-02-16T02:29:26.970607Z",
          "shell.execute_reply.started": "2026-02-16T02:28:48.077020Z"
        },
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "('Page 1: TIN\\nPage 2: Utility Bill\\nPage 3: Loan Application Form\\nPage 4: Loan Application Form\\nPage 5: Loan Application Form\\nPage 6: Loan Application Form\\nPage 7: Pay Slip\\nPage 8: NID\\nPage 9: Bank Statement', [<PIL.PpmImagePlugin.PpmImageFile image mode=RGB size=1653x2339 at 0x7DBDB1F05340>, <PIL.PpmImagePlugin.PpmImageFile image mode=RGB size=2339x1653 at 0x7DBDC822B6B0>, <PIL.PpmImagePlugin.PpmImageFile image mode=RGB size=1653x2339 at 0x7DBDC80D4350>, <PIL.PpmImagePlugin.PpmImageFile image mode=RGB size=1653x2339 at 0x7DBDAE7F51F0>, <PIL.PpmImagePlugin.PpmImageFile image mode=RGB size=1653x2339 at 0x7DBDAE7F6420>, <PIL.PpmImagePlugin.PpmImageFile image mode=RGB size=2339x1653 at 0x7DBDC827DC70>, <PIL.PpmImagePlugin.PpmImageFile image mode=RGB size=1653x2339 at 0x7DBDC827DA00>, <PIL.PpmImagePlugin.PpmImageFile image mode=RGB size=2339x1653 at 0x7DBDB1F04080>, <PIL.PpmImagePlugin.PpmImageFile image mode=RGB size=1653x2339 at 0x7DBDB1F07980>])\n"
          ]
        }
      ],
      "source": [
        "output = classify_doc_with_pages('/kaggle/input/datasets/jawaad512/loan-docs-sample/loantest_v3.pdf', \"Service Holder\")\n",
        "print(output)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# STEP 2: EXTRACTION OF DATA FROM DOCUMENTS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This is a small helper that clears GPU memory after each LLM activity. We call this between document extractions so the GPU does not run out of memory when processing many pages."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2026-02-16T02:29:26.972411Z",
          "iopub.status.busy": "2026-02-16T02:29:26.972208Z",
          "iopub.status.idle": "2026-02-16T02:29:26.977486Z",
          "shell.execute_reply": "2026-02-16T02:29:26.976804Z",
          "shell.execute_reply.started": "2026-02-16T02:29:26.972390Z"
        },
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def clear_gpu():\n",
        "    gc.collect()\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.empty_cache()\n",
        "    alloc = torch.cuda.memory_allocated() / 1024**2 if torch.cuda.is_available() else 0\n",
        "    reserv = torch.cuda.memory_reserved() / 1024**2 if torch.cuda.is_available() else 0\n",
        "    print(\"--- GPU RESET ---\")\n",
        "    print(f\"Allocated: {alloc:.2f} MB\")\n",
        "    print(f\"Reserved:  {reserv:.2f} MB\")\n",
        "    print(\"-----------------\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "For each document type (NID, TIN, Bank Statement, Pay Slip, etc.) we define the **prompts** for the model. \n",
        "\n",
        "Prompt engineering was a crucial part of this project. A precise balance needs to be struck between a few factors:\n",
        "1. Context: Too much context may result in context overload. Too little makes the outcome prone to solely the LLM's understanding of inputs, which is often wrong.\n",
        "2. Specificity: Specific instructions (e.g. keywords, document shape) helped the models not confuse between Pay Slip and Bank Statement, for example. However, hard-coding instructions can be a bad idea for documents of varying types. For example, Bank Statement layouts can be different, so a prompt suggesting an ultra-specific structure will fail on statements not following that structure. Lastly, there is scope for confusion - if I say that you will find 'NID Number' in NID, it will confuse the model because there is NID Number in Loan Application as well. \n",
        "\n",
        "**The trick is to feed the prompt with the most uniquely important and visible identifiers.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2026-02-16T02:29:26.978633Z",
          "iopub.status.busy": "2026-02-16T02:29:26.978324Z",
          "iopub.status.idle": "2026-02-16T02:29:26.990872Z",
          "shell.execute_reply": "2026-02-16T02:29:26.990136Z",
          "shell.execute_reply.started": "2026-02-16T02:29:26.978601Z"
        },
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def get_prompt(doc_type):\n",
        "    doc_type = (doc_type or \"\").strip()\n",
        "    # Bank Statement: structural reconstruction + AccName, AccNo headers \n",
        "    if \"bank statement\" in doc_type.lower():\n",
        "        return (\n",
        "            \"Extract data from this bank statement image. \"\n",
        "            \"First output two header lines: GT_Doc_Statement_AccName: [account holder name], then GT_Doc_Statement_AccNo: [account number]. \"\n",
        "            \"Then output a Markdown table with exactly these columns: | Date | Description | Debit | Credit | Balance |. \"\n",
        "            \"One row per transaction. Use empty cells where a value is not applicable. Return only the headers and the table in Markdown.\"\n",
        "        )\n",
        "\n",
        "    if \"loan application\" in doc_type.lower():\n",
        "        return \"Extract key fields into a Markdown table | Field | Value |. (Loan form handled separately.)\"\n",
        "    # NID (cite: 100, 101)\n",
        "    if doc_type.upper() == \"NID\":\n",
        "        return (\n",
        "            \"Extract ALL of the following from this NID document. Output a Markdown table with columns: | Field | Value |. \"\n",
        "            \"You MUST include exactly these 3 rows:\\n\"\n",
        "            \"- GT_Doc_NID_Name: The full name on the NID\\n\"\n",
        "            \"- GT_Doc_NID_No: The NID number\\n\"\n",
        "            \"- GT_Doc_NID_DOB: The date of birth shown on the NID\\n\"\n",
        "            \"Return only the table. Every row is mandatory.\"\n",
        "        )\n",
        "\n",
        "    if doc_type.upper() == \"TIN\":\n",
        "        return (\n",
        "            \"Extract ALL of the following from this TIN certificate. Output a Markdown table with columns: | Field | Value |. \"\n",
        "            \"You MUST include exactly these 2 rows:\\n\"\n",
        "            \"- GT_Doc_TIN_Name: The full name of the person on the TIN certificate\\n\"\n",
        "            \"- GT_Doc_TIN_Number: The TIN number (12-digit number)\\n\"\n",
        "            \"Return only the table. Every row is mandatory.\"\n",
        "        )\n",
        "\n",
        "    if \"trade license\" in doc_type.lower():\n",
        "        return (\n",
        "            \"Extract from this Trade License. Output a Markdown table with columns: | Field | Value |. \"\n",
        "            \"Rows: GT_Doc_TradeLicense_OrgName, GT_Doc_TradeLicense_LicenseNo. Return only the table.\"\n",
        "        )\n",
        " \n",
        "    if \"utility bill\" in doc_type.lower():\n",
        "        return (\n",
        "            \"Extract ALL of the following from this Utility Bill. Output a Markdown table with columns: | Field | Value |. \"\n",
        "            \"You MUST include exactly these 2 rows:\\n\"\n",
        "            \"- GT_Doc_Utility_Name: The customer/subscriber name who was billed\\n\"\n",
        "            \"- GT_Doc_Utility_Address: The service address or customer address on the bill\\n\"\n",
        "            \"Return only the table. Every row is mandatory.\"\n",
        "        )\n",
        " \n",
        "    if \"pay slip\" in doc_type.lower() or \"payslip\" in doc_type.lower():\n",
        "        return (\n",
        "            \"Extract ALL of the following from this Pay Slip. Output a Markdown table with columns: | Field | Value |. \"\n",
        "            \"You MUST include exactly these 2 rows:\\n\"\n",
        "            \"- GT_Doc_Payslip_EmployerName: The employer or company name on the payslip\\n\"\n",
        "            \"- GT_Doc_Payslip_NetPay: The net pay / take-home amount (the final amount after deductions)\\n\"\n",
        "            \"Return only the table. Every row is mandatory.\"\n",
        "        )\n",
        "\n",
        "    if \"employee id\" in doc_type.lower():\n",
        "        return (\n",
        "            \"Extract from this Employee ID. Output a Markdown table with columns: | Field | Value |. \"\n",
        "            \"Rows: GT_Doc_EmpID_No, GT_Doc_EmpID_OrgName, GT_Doc_EmpID_Designation, GT_Doc_EmpID_Name. Return only the table.\"\n",
        "        )\n",
        "\n",
        "    if \"professional certificate\" in doc_type.lower():\n",
        "        return (\n",
        "            \"Extract from this Professional Certificate. Output a Markdown table with columns: | Field | Value |. \"\n",
        "            \"Rows: GT_Doc_ProfCert_BodyName, GT_Doc_ProfCert_RegNo, GT_Doc_ProfCert_Name. Return only the table.\"\n",
        "        )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The classifier then returns text like “Page 1: TIN\\nPage 2: Utility Bill”. This function parses that text into a list of (page index, document type) pairs so we can loop over each page and run the right extraction for that type."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2026-02-16T02:29:26.992037Z",
          "iopub.status.busy": "2026-02-16T02:29:26.991792Z",
          "iopub.status.idle": "2026-02-16T02:29:27.006927Z",
          "shell.execute_reply": "2026-02-16T02:29:27.006372Z",
          "shell.execute_reply.started": "2026-02-16T02:29:26.992015Z"
        },
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def parse_classification_output(raw_output):\n",
        "    \"\"\"Parse 'Page 1: [Category]\\\\nPage 2: [Category]' into list of (page_index_0based, doc_type).\"\"\"\n",
        "    queue = []\n",
        "    for line in raw_output.strip().split(\"\\n\"):\n",
        "        m = re.match(r\"Page\\s+(\\d+)\\s*:\\s*\\[?(.+?)\\]?\\s*$\", line.strip(), re.I)\n",
        "        if m:\n",
        "            page_num = int(m.group(1))\n",
        "            doc_type = m.group(2).strip()\n",
        "            queue.append((page_num - 1, doc_type))  # 0-based index\n",
        "    return queue"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The model returns extracted data as Markdown tables (e.g. | Field | Value |). This function finds those tables in the text and converts them into pandas DataFrames so we can work with the data in Python (filter, compare, and validate)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2026-02-16T02:29:27.009369Z",
          "iopub.status.busy": "2026-02-16T02:29:27.009116Z",
          "iopub.status.idle": "2026-02-16T02:29:27.023365Z",
          "shell.execute_reply": "2026-02-16T02:29:27.022618Z",
          "shell.execute_reply.started": "2026-02-16T02:29:27.009349Z"
        },
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def markdown_tables_to_dataframes(md_text):\n",
        "    \"\"\"Parse Markdown tables from raw model output into list of Pandas DataFrames (regex-based).\"\"\"\n",
        "    if not md_text or not md_text.strip():\n",
        "        return []\n",
        "    tables = []\n",
        "\n",
        "    table_block = re.findall(\n",
        "        r\"(\\|[^\\n]+\\|\\s*\\n\\|[-:\\s|]+\\|\\s*\\n(?:\\|[^\\n]+\\|\\s*\\n?)*)\",\n",
        "        md_text\n",
        "    )\n",
        "    for block in table_block:\n",
        "        lines = [ln.strip() for ln in block.strip().split(\"\\n\") if ln.strip().startswith(\"|\")]\n",
        "        if len(lines) < 2:\n",
        "            continue\n",
        "        header = [c.strip() for c in lines[0].split(\"|\")[1:-1]]\n",
        "        rows = []\n",
        "        for ln in lines[2:]:  # skip header and separator\n",
        "            cells = [c.strip() for c in ln.split(\"|\")[1:-1]]\n",
        "            if len(cells) == len(header):\n",
        "                rows.append(cells)\n",
        "            elif len(cells) > 0:\n",
        "                rows.append(cells[:len(header)] + [\"\"] * (len(header) - len(cells)))\n",
        "        if header:\n",
        "            tables.append(pd.DataFrame(rows, columns=header))\n",
        "    return tables"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Here, we identify the missing documents."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2026-02-16T02:29:27.024597Z",
          "iopub.status.busy": "2026-02-16T02:29:27.024328Z",
          "iopub.status.idle": "2026-02-16T02:29:27.037376Z",
          "shell.execute_reply": "2026-02-16T02:29:27.036837Z",
          "shell.execute_reply.started": "2026-02-16T02:29:27.024549Z"
        },
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Persona: Service Holder\n",
            "Missing document type(s):\n",
            "  - Employee ID is missing\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "    classification_raw, images = output\n",
        "    queue = parse_classification_output(classification_raw)\n",
        "except NameError:\n",
        "    queue = []\n",
        "    images = []\n",
        "\n",
        "def doc_type_to_results_key(doc_type):\n",
        "    d = (doc_type or \"\").strip().lower()\n",
        "    if \"nid\" == d: return \"NID\"\n",
        "    if \"tin\" == d: return \"TIN\"\n",
        "    if \"bank statement\" in d: return \"Bank Statement\"\n",
        "    if \"loan application\" in d: return \"Loan Application Form\"\n",
        "    if \"trade license\" in d: return \"Trade License\"\n",
        "    if \"utility bill\" in d: return \"Utility Bill\"\n",
        "    if \"pay slip\" in d or \"payslip\" in d: return \"Pay Slip\"\n",
        "    if \"employee id\" in d: return \"Employee ID\"\n",
        "    if \"professional certificate\" in d: return \"Professional Certificate\"\n",
        "    return \"Other\"\n",
        "\n",
        "results = {\n",
        "    \"NID\": [], \"TIN\": [], \"Bank Statement\": [], \"Loan Application Form\": [],\n",
        "    \"Trade License\": [], \"Utility Bill\": [], \"Pay Slip\": [], \"Employee ID\": [],\n",
        "    \"Professional Certificate\": [], \"Other\": []\n",
        "}\n",
        "\n",
        "# --- Missing document check (before extraction; uses classification queue) ---\n",
        "try:\n",
        "    _ = persona\n",
        "except NameError:\n",
        "    persona = \"Service Holder\"  # set to match the persona you used for classification\n",
        "expected = get_persona_categories(persona)\n",
        "found = {doc_type_to_results_key(doc_type) for _, doc_type in queue}\n",
        "missing = [d for d in expected if d not in found]\n",
        "if missing:\n",
        "    print(f\"Persona: {persona}\")\n",
        "    print(\"Missing document type(s):\")\n",
        "    for d in missing:\n",
        "        print(f\"  - {d} is missing\")\n",
        "else:\n",
        "    print(f\"Persona: {persona}\")\n",
        "    print(\"All expected document types present.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Here, we define which fields are mandatory for each document type (e.g. NID must have name, number, DOB). The main function here runs the vision model on one image to extract data. If mandatory fields are missing, it retries once at higher resolution to improve accuracy. Each extracted table is tagged with the source page and document type."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The retry functions were added due to a difficulty I was facing with extracting certain information. In a polished code, it is unlikely to be required."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2026-02-16T02:29:27.038677Z",
          "iopub.status.busy": "2026-02-16T02:29:27.038333Z",
          "iopub.status.idle": "2026-02-16T02:29:27.053504Z",
          "shell.execute_reply": "2026-02-16T02:29:27.052823Z",
          "shell.execute_reply.started": "2026-02-16T02:29:27.038655Z"
        },
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# --- Mandatory field registry per doc type (for retry logic) ---\n",
        "MANDATORY_FIELDS = {\n",
        "    \"NID\":          [\"nid_name\", \"nid_no\", \"nid_dob\"],\n",
        "    \"TIN\":          [\"tin_name\", \"tin_number\"],\n",
        "    \"Utility Bill\": [\"utility_name\", \"utility_address\"],\n",
        "    \"Pay Slip\":     [\"payslip_employername\", \"payslip_netpay\"],\n",
        "}\n",
        "\n",
        "def _check_mandatory(dfs, doc_type):\n",
        "    \"\"\"Return list of mandatory field substrings that are MISSING from dfs.\"\"\"\n",
        "    expected = MANDATORY_FIELDS.get(doc_type, [])\n",
        "    if not expected:\n",
        "        return []\n",
        "    found_fields = set()\n",
        "    for df in dfs:\n",
        "        if \"Field\" in df.columns:\n",
        "            for _, row in df.iterrows():\n",
        "                found_fields.add(str(row[\"Field\"]).lower())\n",
        "    missing = []\n",
        "    for mf in expected:\n",
        "        if not any(mf in f for f in found_fields):\n",
        "            missing.append(mf)\n",
        "    return missing\n",
        "\n",
        "def _vlm_extract(image, prompt, max_pixels, min_pixels, max_new_tokens):\n",
        "    \"\"\"Single VLM call for extraction; returns raw markdown string.\"\"\"\n",
        "    content_list = [\n",
        "        {\"type\": \"image\", \"image\": image, \"max_pixels\": max_pixels, \"min_pixels\": min_pixels},\n",
        "        {\"type\": \"text\", \"text\": prompt}\n",
        "    ]\n",
        "    messages = [{\"role\": \"user\", \"content\": content_list}]\n",
        "    text = processor.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
        "    image_inputs, _ = process_vision_info(messages)\n",
        "    inputs = processor(text=[text], images=image_inputs, padding=True, return_tensors=\"pt\").to(model.device)\n",
        "    with torch.no_grad():\n",
        "        output_ids = model.generate(**inputs, max_new_tokens=max_new_tokens)\n",
        "    generated_ids = [out[len(ins):] for ins, out in zip(inputs.input_ids, output_ids)]\n",
        "    raw_md = processor.batch_decode(generated_ids, skip_special_tokens=True)[0].strip()\n",
        "    del inputs, output_ids, generated_ids, image_inputs\n",
        "    gc.collect()\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.empty_cache()\n",
        "    return raw_md\n",
        "\n",
        "def run_single_extraction(image, doc_type, source_page):\n",
        "    \"\"\"Run VLM on one image; return raw_md and list of DataFrames with Source_Page and Doc_Type.\n",
        "    Includes per-field retry: if mandatory fields are missing, retries at higher resolution.\"\"\"\n",
        "    dt = doc_type.lower()\n",
        "    is_heavy = \"bank statement\" in dt\n",
        "    # Higher res for small docs so fine text is readable; bank statements get full res\n",
        "    max_pixels = 1024 * 1024 if is_heavy else 768 * 768\n",
        "    min_pixels = 512*28*28\n",
        "    max_new_tokens = 4000 if is_heavy else 1024\n",
        "\n",
        "    prompt = get_prompt(doc_type)\n",
        "    raw_md = _vlm_extract(image, prompt, max_pixels, min_pixels, max_new_tokens)\n",
        "    dfs = markdown_tables_to_dataframes(raw_md)\n",
        "\n",
        "    # --- Retry if mandatory fields are missing (once, at higher res) ---\n",
        "    missing = _check_mandatory(dfs, doc_type)\n",
        "    if missing and not is_heavy:\n",
        "        missing_str = \", \".join(missing)\n",
        "        print(f\"  [Retry] Missing mandatory fields ({missing_str}). Retrying at higher resolution...\")\n",
        "        retry_max_px = 1024 * 1024\n",
        "        retry_prompt = (\n",
        "            f\"IMPORTANT: The following fields were NOT found in a previous attempt: {missing_str}. \"\n",
        "            f\"You MUST extract them this time. Look carefully at the entire document.\\n\\n{prompt}\"\n",
        "        )\n",
        "        raw_md2 = _vlm_extract(image, retry_prompt, retry_max_px, min_pixels, max_new_tokens)\n",
        "        dfs2 = markdown_tables_to_dataframes(raw_md2)\n",
        "        still_missing = _check_mandatory(dfs2, doc_type)\n",
        "        if len(still_missing) < len(missing):\n",
        "            print(f\"  [Retry] Improved: recovered {len(missing) - len(still_missing)} field(s).\")\n",
        "            raw_md = raw_md2\n",
        "            dfs = dfs2\n",
        "        else:\n",
        "            print(f\"  [Retry] No improvement; keeping original output.\")\n",
        "\n",
        "    for df in dfs:\n",
        "        df[\"Source_Page\"] = source_page\n",
        "        df[\"Doc_Type\"] = doc_type\n",
        "    return raw_md, dfs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Given the Loan Application Form is a different beast with above 50 extractable information and multiple sections (Applicant Details, Employment, Financials, Banking), I decided to handle it differently. I have defined a prompt and field list for each section and a function that runs the model on each form page. The results from all pages are merged into one table for use in validation.\n",
        "\n",
        "This is a perfect example of when **hard-coded prompts** are required. A bank's loan form layout does not change in short notice, so linking sections to pages was a valid move, alongside specifying exactly what data can be found from where."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Another optimization I have done throughout is to set a **photo resolution ceiling**. The VRAM usage generally explodes when the model deals with high-resolution images (1080p and above). After backtesting, I settled for 720 * 28 * 28 as my image processing format. This means the model will batch 720 images from the input, each having 28*28 resolution, to make processing easier."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2026-02-16T02:29:27.054882Z",
          "iopub.status.busy": "2026-02-16T02:29:27.054549Z",
          "iopub.status.idle": "2026-02-16T02:29:27.075274Z",
          "shell.execute_reply": "2026-02-16T02:29:27.074736Z",
          "shell.execute_reply.started": "2026-02-16T02:29:27.054860Z"
        },
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loan Application Form pipeline ready (Deterministic).\n"
          ]
        }
      ],
      "source": [
        "# ============================================================\n",
        "# CONFIGURATION & TEMPLATES\n",
        "# ============================================================\n",
        "\n",
        "PROMPT_TEMPLATE = (\n",
        "    \"You are an expert data extraction engine specializing in financial documents. \"\n",
        "    \"Your task is to extract data from the provided image of a Loan Application Form \"\n",
        "    \"(Page {page_number}) corresponding to {section_name} into a Markdown table \"\n",
        "    \"with the header | Field | Value |. \"\n",
        "    \"You must follow these strict extraction rules: extract data exactly as it appears \"\n",
        "    \"in the document (including currency symbols, dates, and address formatting), \"\n",
        "    \"but do not hallucinate or include any fields that are blank, marked as 'N/A', \"\n",
        "    \"or not explicitly visible on this specific page. \"\n",
        "    \"Only extract the fields listed for this page: {fields_list}. \"\n",
        "    \"Return ONLY the Markdown table and nothing else—no introductory text, \"\n",
        "    \"closing remarks, or conversational filler.\"\n",
        ")\n",
        "\n",
        "LOAN_FORM_MAX_PIXELS = 720 * 28 * 28\n",
        "\n",
        "# Mapping relative page index (1-4) to section keys\n",
        "PAGE_TO_SECTION_MAP = {\n",
        "    1: \"A\",  # Applicant Details\n",
        "    2: \"B\",  # Employment\n",
        "    3: \"D\",  # Financials (Merged C & D)\n",
        "    4: \"E\"   # Banking & References\n",
        "}\n",
        "\n",
        "LOAN_FORM_SECTIONS = {\n",
        "    \"A\": {\n",
        "        \"name\": \"Applicant Details & Loan Info\",\n",
        "        \"fields_list\": (\n",
        "            \"SL, Persona, Amount sought (BDT), Tenure (Months), Offered Security, \"\n",
        "            \"Applicant Name, Father's Name, Mother's Name, Marital Status, \"\n",
        "            \"Applicant's Date of Birth, Gender, Educational Level, Number of Dependents, \"\n",
        "            \"TIN No., NID No., Present Address, Permanent Address, Mobile, E-mail.\"\n",
        "        ),\n",
        "        \"max_tokens\": 500,\n",
        "    },\n",
        "    \"B\": {\n",
        "        \"name\": \"Employment & Business\",\n",
        "        \"fields_list\": (\n",
        "            \"Name of Present Employer, Designation, Date of Joining (Present Employer), \"\n",
        "            \"Profession (Self-Employed), No. of years in Practice, Clinic/Chamber/Firm/Office Name, \"\n",
        "            \"Organization Name (Businessman), Organization Address (Businessman), \"\n",
        "            \"Years in Present Business, Total Length of Business.\"\n",
        "        ),\n",
        "        \"max_tokens\": 350,\n",
        "    },\n",
        "    \"D\": {\n",
        "        \"name\": \"Financial Information (Income, Expenditure, Assets & Liabilities)\",\n",
        "        \"fields_list\": (\n",
        "            \"Monthly Income (Salary, Business, Rental, Interest, Other, Total X), \"\n",
        "            \"Monthly Expenditure (Loan repayment, Cards, Rent/Utilities, Living, \"\n",
        "            \"Educational, Other, Total Y), Uncommitted Income (X-Y), \"\n",
        "            \"Assets (Savings, Current, Fixed Deposit, Bonds, Shares, Land/Building, \"\n",
        "            \"Vehicles, Business Investment, Precious Metals, Total Assets), \"\n",
        "            \"Liabilities (Bank Loans, Credit Cards, Other, Total Liability, Net Worth).\"\n",
        "        ),\n",
        "        \"max_tokens\": 700,\n",
        "    },\n",
        "    \"E\": {\n",
        "        \"name\": \"Banking, Credit Cards & References\",\n",
        "        \"fields_list\": (\n",
        "            \"Bank Name, Branch, Account No., Type, Average Balance, \"\n",
        "            \"Lender Name, Branch, Account No., Amount Outstanding, Monthly Repayment, \"\n",
        "            \"Has Credit Card, Issuing Institution, Card No., Limit, Outstanding, \"\n",
        "            \"Reference Name, Relationship, Address, Phone, Profession, Email.\"\n",
        "        ),\n",
        "        \"max_tokens\": 500,\n",
        "    },\n",
        "}\n",
        "\n",
        "# ============================================================\n",
        "# HELPER FUNCTIONS\n",
        "# ============================================================\n",
        "\n",
        "def _vlm_call(image, prompt_text, max_new_tokens, max_pixels=720*28*28):\n",
        "    \"\"\"\n",
        "    Low-level single VLM call. Returns raw decoded string.\n",
        "    Uses max_pixels to resize image and limit GPU memory (critical for OOM avoidance).\n",
        "    \"\"\"\n",
        "    content_list = [\n",
        "        {\"type\": \"image\", \"image\": image, \"max_pixels\": max_pixels},\n",
        "        {\"type\": \"text\", \"text\": prompt_text},\n",
        "    ]\n",
        "    messages = [{\"role\": \"user\", \"content\": content_list}]\n",
        "    \n",
        "    text = processor.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
        "    image_inputs, _ = process_vision_info(messages)\n",
        "    inputs = processor(\n",
        "        text=[text], \n",
        "        images=image_inputs, \n",
        "        padding=True, \n",
        "        return_tensors=\"pt\"\n",
        "    ).to(model.device)\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        output_ids = model.generate(**inputs, max_new_tokens=max_new_tokens)\n",
        "    \n",
        "    generated_ids = [out[len(ins):] for ins, out in zip(inputs.input_ids, output_ids)]\n",
        "    out_text = processor.batch_decode(generated_ids, skip_special_tokens=True)[0].strip()\n",
        "    del inputs, output_ids, generated_ids, image_inputs\n",
        "    gc.collect()\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.empty_cache()\n",
        "    return out_text\n",
        "\n",
        "def extract_loan_page_data(image, page_index):\n",
        "    \"\"\"\n",
        "    Constructs the prompt and extracts data for a specific page index.\n",
        "    \"\"\"\n",
        "    # 1. Identify Section\n",
        "    section_key = PAGE_TO_SECTION_MAP.get(page_index)\n",
        "    if not section_key:\n",
        "        print(f\"  [Warning] No section map found for relative page {page_index}. Skipping.\")\n",
        "        return None, []\n",
        "\n",
        "    section_config = LOAN_FORM_SECTIONS[section_key]\n",
        "    \n",
        "    # 2. Build Deterministic Prompt\n",
        "    final_prompt = PROMPT_TEMPLATE.format(\n",
        "        page_number=page_index,\n",
        "        section_name=section_config[\"name\"],\n",
        "        fields_list=section_config[\"fields_list\"]\n",
        "    )\n",
        "\n",
        "    # 3. Call VLM (with capped image size to avoid OOM)\n",
        "    print(f\"  Targeting Section {section_key}: {section_config['name']}\")\n",
        "    raw_md = _vlm_call(image, final_prompt, section_config[\"max_tokens\"], max_pixels=LOAN_FORM_MAX_PIXELS)\n",
        "    \n",
        "    # 4. Parse Table\n",
        "    # (Assuming markdown_tables_to_dataframes is available in your utils)\n",
        "    dfs = markdown_tables_to_dataframes(raw_md)\n",
        "    rows = []\n",
        "    for df in dfs:\n",
        "        if not df.empty and \"Field\" in df.columns and \"Value\" in df.columns:\n",
        "            rows.extend(df.to_dict(\"records\"))\n",
        "            \n",
        "    return raw_md, rows\n",
        "\n",
        "# ============================================================\n",
        "# MAIN PIPELINE\n",
        "# ============================================================\n",
        "\n",
        "def run_loan_form_extraction(loan_pages):\n",
        "    \"\"\"\n",
        "    Deterministic pipeline for Loan Application Form pages.\n",
        "    loan_pages: list of (source_page_number, PIL_image)\n",
        "    \n",
        "    NOTE: We iterate with a relative index (1, 2, 3, 4) to map to sections,\n",
        "    regardless of the absolute page number in the original PDF.\n",
        "    \"\"\"\n",
        "    all_raw = []\n",
        "    all_rows = []\n",
        "\n",
        "    print(f\"Starting Deterministic Extraction on {len(loan_pages)} pages...\")\n",
        "\n",
        "    # enumerate start=1 gives us the relative index (1st page, 2nd page, etc.)\n",
        "    for relative_idx, (source_page_num, image) in enumerate(loan_pages, start=1):\n",
        "        print(f\"\\n{'='*60}\")\n",
        "        print(f\"Processing Loan Form Page {relative_idx} (Original PDF Page {source_page_num})\")\n",
        "        print(f\"{'='*60}\")\n",
        "\n",
        "        try:\n",
        "            raw_md, rows = extract_loan_page_data(image, relative_idx)\n",
        "        except torch.cuda.OutOfMemoryError:\n",
        "            print(f\"  OOM on page {relative_idx} — skipping. Clearing GPU...\")\n",
        "            clear_gpu()\n",
        "            continue\n",
        "        \n",
        "        if raw_md:\n",
        "            section_name = LOAN_FORM_SECTIONS[PAGE_TO_SECTION_MAP[relative_idx]][\"name\"]\n",
        "            header = f\"--- Page {source_page_num} (Form Page {relative_idx}) | {section_name} ---\"\n",
        "            all_raw.append(f\"{header}\\n{raw_md}\")\n",
        "            print(\"  Raw markdown (this page):\")\n",
        "            print(raw_md)\n",
        "            if rows:\n",
        "                all_rows.extend(rows)\n",
        "                print(f\"  Extracted {len(rows)} fields:\")\n",
        "                for r in rows:\n",
        "                    print(f\"    | {r.get('Field','')}: {r.get('Value','')}\")\n",
        "            else:\n",
        "                print(\"  Warning: No valid table rows found in output.\")\n",
        "        \n",
        "        clear_gpu()\n",
        "\n",
        "    # Merge Results\n",
        "    merged_raw = \"\\n\\n\".join(all_raw)\n",
        "    if all_rows:\n",
        "        merged_df = pd.DataFrame(all_rows)\n",
        "        merged_df[\"Doc_Type\"] = \"Loan Application Form\"\n",
        "        return merged_raw, merged_df\n",
        "    \n",
        "    return merged_raw, pd.DataFrame()\n",
        "\n",
        "print(\"Loan Application Form pipeline ready (Deterministic).\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Here, we loop over every page that was classified (except Loan Application Form pages). For each page we call the extraction function, which sends the page image and the right prompt to the model, then we store the raw output and the parsed tables in the results dictionary. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2026-02-16T02:29:27.076500Z",
          "iopub.status.busy": "2026-02-16T02:29:27.076196Z",
          "iopub.status.idle": "2026-02-16T02:32:48.587769Z",
          "shell.execute_reply": "2026-02-16T02:32:48.587044Z",
          "shell.execute_reply.started": "2026-02-16T02:29:27.076470Z"
        },
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "Extracting Page 1 | Doc_Type: TIN\n",
            "============================================================\n",
            "1. Raw Markdown:\n",
            " | Field | Value |\n",
            "| --- | --- |\n",
            "| GT_Doc_TIN_Name | Habibur Rahman |\n",
            "| GT_Doc_TIN_Number | 956146156867 |\n",
            "\n",
            "2. DataFrame (table 1) head():\n",
            "                Field           Value  Source_Page Doc_Type\n",
            "0    GT_Doc_TIN_Name  Habibur Rahman            1      TIN\n",
            "1  GT_Doc_TIN_Number    956146156867            1      TIN\n",
            "--- GPU RESET ---\n",
            "Allocated: 4471.58 MB\n",
            "Reserved:  5658.00 MB\n",
            "-----------------\n",
            "\n",
            "============================================================\n",
            "Extracting Page 2 | Doc_Type: Utility Bill\n",
            "============================================================\n",
            "1. Raw Markdown:\n",
            " | Field | Value |\n",
            "| --- | --- |\n",
            "| GT_Doc_Utility_Name | Tamara Smith |\n",
            "| GT_Doc_Utility_Address | Holding No. 49, New PalashRoad, FulDerga, Pencheghat, 3038 |\n",
            "\n",
            "2. DataFrame (table 1) head():\n",
            "                     Field                                              Value  \\\n",
            "0     GT_Doc_Utility_Name                                       Tamara Smith   \n",
            "1  GT_Doc_Utility_Address  Holding No. 49, New PalashRoad, FulDerga, Penc...   \n",
            "\n",
            "   Source_Page      Doc_Type  \n",
            "0            2  Utility Bill  \n",
            "1            2  Utility Bill  \n",
            "--- GPU RESET ---\n",
            "Allocated: 4471.58 MB\n",
            "Reserved:  5658.00 MB\n",
            "-----------------\n",
            "\n",
            "============================================================\n",
            "Extracting Page 7 | Doc_Type: Pay Slip\n",
            "============================================================\n",
            "1. Raw Markdown:\n",
            " | Field | Value |\n",
            "| --- | --- |\n",
            "| GT_Doc_Payslip_EmployerName | PEREZ, HARVEY AND STOKES |\n",
            "| GT_Doc_Payslip_NetPay | 46274.0 |\n",
            "\n",
            "2. DataFrame (table 1) head():\n",
            "                          Field                     Value  Source_Page  \\\n",
            "0  GT_Doc_Payslip_EmployerName  PEREZ, HARVEY AND STOKES            7   \n",
            "1        GT_Doc_Payslip_NetPay                   46274.0            7   \n",
            "\n",
            "   Doc_Type  \n",
            "0  Pay Slip  \n",
            "1  Pay Slip  \n",
            "--- GPU RESET ---\n",
            "Allocated: 4471.58 MB\n",
            "Reserved:  5658.00 MB\n",
            "-----------------\n",
            "\n",
            "============================================================\n",
            "Extracting Page 8 | Doc_Type: NID\n",
            "============================================================\n",
            "1. Raw Markdown:\n",
            " | Field | Value |\n",
            "| --- | --- |\n",
            "| GT_Doc_NID_Name | Tamara Smith |\n",
            "| GT_Doc_NID_No | 45345495959 |\n",
            "| GT_Doc_NID_DOB | 1978-01-01 |\n",
            "\n",
            "2. DataFrame (table 1) head():\n",
            "              Field         Value  Source_Page Doc_Type\n",
            "0  GT_Doc_NID_Name  Tamara Smith            8      NID\n",
            "1    GT_Doc_NID_No   45345495959            8      NID\n",
            "2   GT_Doc_NID_DOB    1978-01-01            8      NID\n",
            "--- GPU RESET ---\n",
            "Allocated: 4471.58 MB\n",
            "Reserved:  5658.00 MB\n",
            "-----------------\n",
            "\n",
            "============================================================\n",
            "Extracting Page 9 | Doc_Type: Bank Statement\n",
            "============================================================\n",
            "1. Raw Markdown:\n",
            " GT_Doc_Statement_AccName: Tamara Smith  \n",
            "GT_Doc_Statement_AccNo: 6918536146  \n",
            "\n",
            "| Date       | Description                                      | Debit   | Credit   | Balance     |\n",
            "|------------|--------------------------------------------------|---------|----------|-------------|\n",
            "| 01-AUG-25  | BALANCE FORWARD                                  |         |          | 673,091.00 |\n",
            "| 05-AUG-25  | SALARY/Perez, Harvey and Stokes                  |         | 41,427.00| 714,518.00 |\n",
            "| 12-AUG-25  | CC PMT                                           | 19,148.00|         | 695,370.00 |\n",
            "| 16-AUG-25  | EFT/RENT                                         | 22,216.00|         | 673,154.00 |\n",
            "| 20-AUG-25  | EFT/OTHER INCOME                                 |         | 12,581.00| 685,735.00 |\n",
            "| 05-SEP-25  | SALARY/Perez, Harvey and Stokes                  |         | 49,443.00| 735,180.00 |\n",
            "| 12-SEP-25  | TRF/LOAN REPAY                                   | 21,191.00|         | 713,989.00 |\n",
            "| 16-SEP-25  | BILLPAY/UTILITY                                  | 21,700.00|         | 692,289.00 |\n",
            "| 20-SEP-25  | TRF/INCOMING                                     |         | 5,411.00 | 697,700.00 |\n",
            "| 05-OCT-25  | SALARY/Perez, Harvey and Stokes                  |         | 41,510.00| 739,210.00 |\n",
            "| 12-OCT-25  | POS/SHOPPING                                     | 12,440.00|         | 726,770.00 |\n",
            "| 16-OCT-25  | BILLPAY/UTILITY                                  | 15,214.00|         | 711,556.00 |\n",
            "| 20-OCT-25  | TRF/INCOMING                                     |         | 4,000.00 | 715,556.00 |\n",
            "| 23-OCT-25  | TRF/LOAN REPAY                                   | 15,265.00|         | 700,291.00 |\n",
            "| 05-NOV-25  | SALARY/Perez, Harvey and Stokes                  |         | 36,259.00| 736,550.00 |\n",
            "| 12-NOV-25  | TRF/LOAN REPAY                                   | 12,496.00|         | 724,054.00 |\n",
            "| 16-NOV-25  | EFT/RENT                                         | 10,949.00|         | 713,105.00 |\n",
            "| 20-NOV-25  | TRF/INCOMING                                     |         | 9,535.00 | 722,640.00 |\n",
            "| 23-NOV-25  | TRF/LOAN REPAY                                   | 12,184.00|         | 710,456.00 |\n",
            "| 28-NOV-25  | POS/SHOPPING                                     | 10,637.00|         | 699,819.00 |\n",
            "| 05-DEC-25  | SALARY/Perez, Harvey and Stokes                  |         | 37,754.00| 737,573.00 |\n",
            "| 12-DEC-25  | EFT/RENT                                         | 19,451.00|         | 718,122.00 |\n",
            "| 16-DEC-25  | BILLPAY/UTILITY                                  | 24,767.00|         | 693,355.00 |\n",
            "| 20-DEC-25  | EFT/OTHER INCOME                                 |         | 9,677.00 | 703,032.00 |\n",
            "| 05-JAN-26  | SALARY/Perez, Harvey and Stokes                  |         | 41,207.00| 744,239.00 |\n",
            "| 12-JAN-26  | CASH DEP                                         |         | 13,458.00| 757,697.00 |\n",
            "| 12-JAN-26  | BILLPAY/UTILITY                                  | 16,150.00|         | 741,547.00 |\n",
            "| 15-JAN-26  | TRF/LOAN REPAY                                   | 17,101.00|         | 724,446.00 |\n",
            "| 15-JAN-26  | POS/SHOPPING                                     | 16,092.00|         | 708,354.00 |\n",
            "| 15-JAN-26  | TRF/INCOMING                                     |         | 205,000.00| 913,354.00 |\n",
            "\n",
            "2. DataFrame (table 1) head():\n",
            "         Date                      Description      Debit     Credit  \\\n",
            "0  01-AUG-25                  BALANCE FORWARD                         \n",
            "1  05-AUG-25  SALARY/Perez, Harvey and Stokes             41,427.00   \n",
            "2  12-AUG-25                           CC PMT  19,148.00              \n",
            "3  16-AUG-25                         EFT/RENT  22,216.00              \n",
            "4  20-AUG-25                 EFT/OTHER INCOME             12,581.00   \n",
            "\n",
            "      Balance  Source_Page        Doc_Type  \n",
            "0  673,091.00            9  Bank Statement  \n",
            "1  714,518.00            9  Bank Statement  \n",
            "2  695,370.00            9  Bank Statement  \n",
            "3  673,154.00            9  Bank Statement  \n",
            "4  685,735.00            9  Bank Statement  \n",
            "--- GPU RESET ---\n",
            "Allocated: 4471.58 MB\n",
            "Reserved:  5658.00 MB\n",
            "-----------------\n"
          ]
        }
      ],
      "source": [
        "raw_outputs = {}\n",
        "\n",
        "# --- Execution loop 1: classified document pages (queue from main PDF) ---\n",
        "# Loan Application Form is skipped here\n",
        "for page_idx, doc_type in queue:\n",
        "    if page_idx >= len(images):\n",
        "        continue\n",
        "    if \"loan application\" in doc_type.lower():\n",
        "        continue  # skip; test separately\n",
        "    source_page = page_idx + 1\n",
        "    print(f\"\\n{'='*60}\\nExtracting Page {source_page} | Doc_Type: {doc_type}\\n{'='*60}\")\n",
        "    raw_md, dfs = run_single_extraction(images[page_idx], doc_type, source_page)\n",
        "    print(\"1. Raw Markdown:\\n\", raw_md)\n",
        "    key = doc_type_to_results_key(doc_type)\n",
        "    raw_outputs.setdefault(key, []).append(raw_md)\n",
        "    for i, df in enumerate(dfs):\n",
        "        results[key].append(df)\n",
        "        print(f\"\\n2. DataFrame (table {i+1}) head():\\n\", df.head())\n",
        "    clear_gpu()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "(I looped Loan Application Form separately. It was taking some time to run, troubleshoot/reprompt and re-run as opposed to the rest of the documents.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2026-02-16T02:32:48.588961Z",
          "iopub.status.busy": "2026-02-16T02:32:48.588683Z",
          "iopub.status.idle": "2026-02-16T02:34:57.431190Z",
          "shell.execute_reply": "2026-02-16T02:34:57.430448Z",
          "shell.execute_reply.started": "2026-02-16T02:32:48.588937Z"
        },
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loan Application Form pages found: [3, 4, 5, 6]\n",
            "Starting Deterministic Extraction on 4 pages...\n",
            "\n",
            "============================================================\n",
            "Processing Loan Form Page 1 (Original PDF Page 3)\n",
            "============================================================\n",
            "  Targeting Section A: Applicant Details & Loan Info\n",
            "  Raw markdown (this page):\n",
            "| Field | Value |\n",
            "|---|---|\n",
            "| Persona | Service Holder |\n",
            "| Amount sought (BDT) | 3252230 |\n",
            "| Tenure (Months) | 48 |\n",
            "| Offered Security | Land |\n",
            "| Applicant Name | Tamara Smit |\n",
            "| Father's Name | Jason Watson |\n",
            "| Mother's Name | Elizabeth Weaver |\n",
            "| Marital Status | Married |\n",
            "| Applicant's Date of Birth | 13-08-1978 |\n",
            "| Gender | Male |\n",
            "| Educational Level | SSC |\n",
            "| Number of Dependents | 3 |\n",
            "| TIN No. | 966146156867 |\n",
            "| NID No. | 54345495950 |\n",
            "| Present Address | Holding No. 49, New Palash Road, Ful Danga, Panchagarh, 3038. |\n",
            "| Permanent Address | House no 874, East Kamalkali, Mohammadpur, Shariatpur, 2446 |\n",
            "| Mobile | 809-924-4745 x993 |\n",
            "| E-mail | brandon06@example.com |\n",
            "  Extracted 18 fields:\n",
            "    | Persona: Service Holder\n",
            "    | Amount sought (BDT): 3252230\n",
            "    | Tenure (Months): 48\n",
            "    | Offered Security: Land\n",
            "    | Applicant Name: Tamara Smit\n",
            "    | Father's Name: Jason Watson\n",
            "    | Mother's Name: Elizabeth Weaver\n",
            "    | Marital Status: Married\n",
            "    | Applicant's Date of Birth: 13-08-1978\n",
            "    | Gender: Male\n",
            "    | Educational Level: SSC\n",
            "    | Number of Dependents: 3\n",
            "    | TIN No.: 966146156867\n",
            "    | NID No.: 54345495950\n",
            "    | Present Address: Holding No. 49, New Palash Road, Ful Danga, Panchagarh, 3038.\n",
            "    | Permanent Address: House no 874, East Kamalkali, Mohammadpur, Shariatpur, 2446\n",
            "    | Mobile: 809-924-4745 x993\n",
            "    | E-mail: brandon06@example.com\n",
            "--- GPU RESET ---\n",
            "Allocated: 4471.58 MB\n",
            "Reserved:  5658.00 MB\n",
            "-----------------\n",
            "\n",
            "============================================================\n",
            "Processing Loan Form Page 2 (Original PDF Page 4)\n",
            "============================================================\n",
            "  Targeting Section B: Employment & Business\n",
            "  Raw markdown (this page):\n",
            "| Field | Value |\n",
            "| --- | --- |\n",
            "| Name of Present Employer | Parez, Harvey and Stokes |\n",
            "| Designation | Chief Tiktok Officer |\n",
            "| Date of Joining (Present Employer) | 18-06-2015 |\n",
            "| Profession (Self-Employed) | N/A |\n",
            "| No. of years in Practice | N/A |\n",
            "| Clinic/Chamber/Firm/Office Name | N/A |\n",
            "| Organization Name (Businessman) | N/A |\n",
            "| Organization Address (Businessman) | N/A |\n",
            "| Years in Present Business | N/A |\n",
            "| Total Length of Business | N/A |\n",
            "  Extracted 10 fields:\n",
            "    | Name of Present Employer: Parez, Harvey and Stokes\n",
            "    | Designation: Chief Tiktok Officer\n",
            "    | Date of Joining (Present Employer): 18-06-2015\n",
            "    | Profession (Self-Employed): N/A\n",
            "    | No. of years in Practice: N/A\n",
            "    | Clinic/Chamber/Firm/Office Name: N/A\n",
            "    | Organization Name (Businessman): N/A\n",
            "    | Organization Address (Businessman): N/A\n",
            "    | Years in Present Business: N/A\n",
            "    | Total Length of Business: N/A\n",
            "--- GPU RESET ---\n",
            "Allocated: 4471.58 MB\n",
            "Reserved:  5658.00 MB\n",
            "-----------------\n",
            "\n",
            "============================================================\n",
            "Processing Loan Form Page 3 (Original PDF Page 5)\n",
            "============================================================\n",
            "  Targeting Section D: Financial Information (Income, Expenditure, Assets & Liabilities)\n",
            "  Raw markdown (this page):\n",
            "| Field | Value |\n",
            "| --- | --- |\n",
            "| Monthly Income (Amount in Tk.) | Amount (BDT) |\n",
            "| Salary | 49855 |\n",
            "| Business income | 0 |\n",
            "| Income from Self-Employment | 0 |\n",
            "| Rental Income | 20000 |\n",
            "| Interest earning | 4693 |\n",
            "| Any other source | 3385 |\n",
            "| Total Income (X) | 77933 |\n",
            "| Monthly Expenditure (Amount in Tk.) | Amount (BDT) |\n",
            "| Loan repayment | 11798 |\n",
            "| Other loan & credit Card Installments | 7957 |\n",
            "| Rent and Utilities | 37948 |\n",
            "| Living expenses (food, education, clothing, etc.) | 51887 |\n",
            "| Educational Expenses | 16881 |\n",
            "| Any other | 4396 |\n",
            "| Total Expenditure (Y) | 136867 |\n",
            "| Monthly uncommitted Income (X - Y) in BDT | -52934 |\n",
            "| Assets (Amount in Tk.) | Amount (BDT) |\n",
            "| Savings A/C with Banks | 537310 |\n",
            "| Current A/C with Banks | 1058585 |\n",
            "| Fixed deposit with Banks | 1691594 |\n",
            "| Bonds | 158122 |\n",
            "| Shares / certificates | 67119 |\n",
            "| Land & building | 22091229 |\n",
            "| Motor vehicles | 3922670 |\n",
            "| Investment in business | 12393826 |\n",
            "| Precious metals | 239326 |\n",
            "| Total Assets (X) | 42140284 |\n",
            "| Liabilities (Amount in Tk.) | Amount (BDT) |\n",
            "| Loan from Banks | 514149 |\n",
            "| Credit Card Liability | 50529 |\n",
            "| Other liabilities (including any guarantee given) | 249874 |\n",
            "| Total Liability (Y) | 814522 |\n",
            "| Net Worth (X - Y) | 41325732 |\n",
            "  Extracted 34 fields:\n",
            "    | Monthly Income (Amount in Tk.): Amount (BDT)\n",
            "    | Salary: 49855\n",
            "    | Business income: 0\n",
            "    | Income from Self-Employment: 0\n",
            "    | Rental Income: 20000\n",
            "    | Interest earning: 4693\n",
            "    | Any other source: 3385\n",
            "    | Total Income (X): 77933\n",
            "    | Monthly Expenditure (Amount in Tk.): Amount (BDT)\n",
            "    | Loan repayment: 11798\n",
            "    | Other loan & credit Card Installments: 7957\n",
            "    | Rent and Utilities: 37948\n",
            "    | Living expenses (food, education, clothing, etc.): 51887\n",
            "    | Educational Expenses: 16881\n",
            "    | Any other: 4396\n",
            "    | Total Expenditure (Y): 136867\n",
            "    | Monthly uncommitted Income (X - Y) in BDT: -52934\n",
            "    | Assets (Amount in Tk.): Amount (BDT)\n",
            "    | Savings A/C with Banks: 537310\n",
            "    | Current A/C with Banks: 1058585\n",
            "    | Fixed deposit with Banks: 1691594\n",
            "    | Bonds: 158122\n",
            "    | Shares / certificates: 67119\n",
            "    | Land & building: 22091229\n",
            "    | Motor vehicles: 3922670\n",
            "    | Investment in business: 12393826\n",
            "    | Precious metals: 239326\n",
            "    | Total Assets (X): 42140284\n",
            "    | Liabilities (Amount in Tk.): Amount (BDT)\n",
            "    | Loan from Banks: 514149\n",
            "    | Credit Card Liability: 50529\n",
            "    | Other liabilities (including any guarantee given): 249874\n",
            "    | Total Liability (Y): 814522\n",
            "    | Net Worth (X - Y): 41325732\n",
            "--- GPU RESET ---\n",
            "Allocated: 4471.58 MB\n",
            "Reserved:  5658.00 MB\n",
            "-----------------\n",
            "\n",
            "============================================================\n",
            "Processing Loan Form Page 4 (Original PDF Page 6)\n",
            "============================================================\n",
            "  Targeting Section E: Banking, Credit Cards & References\n",
            "  Raw markdown (this page):\n",
            "| Field | Value |\n",
            "| --- | --- |\n",
            "| Bank Name | Obrien and Sons |\n",
            "| Branch | Pirojpur |\n",
            "| Account No. | 6918536146 |\n",
            "| Type | Current |\n",
            "| Average Balance | 703354 |\n",
            "| Lender Name | Campos-Thomas |\n",
            "| Branch | Joypurhat |\n",
            "| Account No. | 4476029692 |\n",
            "| Amount Outstanding | 213706 |\n",
            "| Monthly Repayment | 17491 |\n",
            "| Has Credit Card | Yes |\n",
            "| Issuing Institution | Doyle Group |\n",
            "| Card No. | 2183-7731-5204-7655 |\n",
            "| Limit | 194283 |\n",
            "| Outstanding | 109721 |\n",
            "  Extracted 15 fields:\n",
            "    | Bank Name: Obrien and Sons\n",
            "    | Branch: Pirojpur\n",
            "    | Account No.: 6918536146\n",
            "    | Type: Current\n",
            "    | Average Balance: 703354\n",
            "    | Lender Name: Campos-Thomas\n",
            "    | Branch: Joypurhat\n",
            "    | Account No.: 4476029692\n",
            "    | Amount Outstanding: 213706\n",
            "    | Monthly Repayment: 17491\n",
            "    | Has Credit Card: Yes\n",
            "    | Issuing Institution: Doyle Group\n",
            "    | Card No.: 2183-7731-5204-7655\n",
            "    | Limit: 194283\n",
            "    | Outstanding: 109721\n",
            "--- GPU RESET ---\n",
            "Allocated: 4471.58 MB\n",
            "Reserved:  5658.00 MB\n",
            "-----------------\n",
            "\n",
            "============================================================\n",
            "Loan Application Form — Merged DataFrame:\n",
            "============================================================\n",
            "                                            Field                                                         Value              Doc_Type\n",
            "                                          Persona                                                Service Holder Loan Application Form\n",
            "                              Amount sought (BDT)                                                       3252230 Loan Application Form\n",
            "                                  Tenure (Months)                                                            48 Loan Application Form\n",
            "                                 Offered Security                                                          Land Loan Application Form\n",
            "                                   Applicant Name                                                   Tamara Smit Loan Application Form\n",
            "                                    Father's Name                                                  Jason Watson Loan Application Form\n",
            "                                    Mother's Name                                              Elizabeth Weaver Loan Application Form\n",
            "                                   Marital Status                                                       Married Loan Application Form\n",
            "                        Applicant's Date of Birth                                                    13-08-1978 Loan Application Form\n",
            "                                           Gender                                                          Male Loan Application Form\n",
            "                                Educational Level                                                           SSC Loan Application Form\n",
            "                             Number of Dependents                                                             3 Loan Application Form\n",
            "                                          TIN No.                                                  966146156867 Loan Application Form\n",
            "                                          NID No.                                                   54345495950 Loan Application Form\n",
            "                                  Present Address Holding No. 49, New Palash Road, Ful Danga, Panchagarh, 3038. Loan Application Form\n",
            "                                Permanent Address   House no 874, East Kamalkali, Mohammadpur, Shariatpur, 2446 Loan Application Form\n",
            "                                           Mobile                                             809-924-4745 x993 Loan Application Form\n",
            "                                           E-mail                                         brandon06@example.com Loan Application Form\n",
            "                         Name of Present Employer                                      Parez, Harvey and Stokes Loan Application Form\n",
            "                                      Designation                                          Chief Tiktok Officer Loan Application Form\n",
            "               Date of Joining (Present Employer)                                                    18-06-2015 Loan Application Form\n",
            "                       Profession (Self-Employed)                                                           N/A Loan Application Form\n",
            "                         No. of years in Practice                                                           N/A Loan Application Form\n",
            "                  Clinic/Chamber/Firm/Office Name                                                           N/A Loan Application Form\n",
            "                  Organization Name (Businessman)                                                           N/A Loan Application Form\n",
            "               Organization Address (Businessman)                                                           N/A Loan Application Form\n",
            "                        Years in Present Business                                                           N/A Loan Application Form\n",
            "                         Total Length of Business                                                           N/A Loan Application Form\n",
            "                   Monthly Income (Amount in Tk.)                                                  Amount (BDT) Loan Application Form\n",
            "                                           Salary                                                         49855 Loan Application Form\n",
            "                                  Business income                                                             0 Loan Application Form\n",
            "                      Income from Self-Employment                                                             0 Loan Application Form\n",
            "                                    Rental Income                                                         20000 Loan Application Form\n",
            "                                 Interest earning                                                          4693 Loan Application Form\n",
            "                                 Any other source                                                          3385 Loan Application Form\n",
            "                                 Total Income (X)                                                         77933 Loan Application Form\n",
            "              Monthly Expenditure (Amount in Tk.)                                                  Amount (BDT) Loan Application Form\n",
            "                                   Loan repayment                                                         11798 Loan Application Form\n",
            "            Other loan & credit Card Installments                                                          7957 Loan Application Form\n",
            "                               Rent and Utilities                                                         37948 Loan Application Form\n",
            "Living expenses (food, education, clothing, etc.)                                                         51887 Loan Application Form\n",
            "                             Educational Expenses                                                         16881 Loan Application Form\n",
            "                                        Any other                                                          4396 Loan Application Form\n",
            "                            Total Expenditure (Y)                                                        136867 Loan Application Form\n",
            "        Monthly uncommitted Income (X - Y) in BDT                                                        -52934 Loan Application Form\n",
            "                           Assets (Amount in Tk.)                                                  Amount (BDT) Loan Application Form\n",
            "                           Savings A/C with Banks                                                        537310 Loan Application Form\n",
            "                           Current A/C with Banks                                                       1058585 Loan Application Form\n",
            "                         Fixed deposit with Banks                                                       1691594 Loan Application Form\n",
            "                                            Bonds                                                        158122 Loan Application Form\n",
            "                            Shares / certificates                                                         67119 Loan Application Form\n",
            "                                  Land & building                                                      22091229 Loan Application Form\n",
            "                                   Motor vehicles                                                       3922670 Loan Application Form\n",
            "                           Investment in business                                                      12393826 Loan Application Form\n",
            "                                  Precious metals                                                        239326 Loan Application Form\n",
            "                                 Total Assets (X)                                                      42140284 Loan Application Form\n",
            "                      Liabilities (Amount in Tk.)                                                  Amount (BDT) Loan Application Form\n",
            "                                  Loan from Banks                                                        514149 Loan Application Form\n",
            "                            Credit Card Liability                                                         50529 Loan Application Form\n",
            "Other liabilities (including any guarantee given)                                                        249874 Loan Application Form\n",
            "                              Total Liability (Y)                                                        814522 Loan Application Form\n",
            "                                Net Worth (X - Y)                                                      41325732 Loan Application Form\n",
            "                                        Bank Name                                               Obrien and Sons Loan Application Form\n",
            "                                           Branch                                                      Pirojpur Loan Application Form\n",
            "                                      Account No.                                                    6918536146 Loan Application Form\n",
            "                                             Type                                                       Current Loan Application Form\n",
            "                                  Average Balance                                                        703354 Loan Application Form\n",
            "                                      Lender Name                                                 Campos-Thomas Loan Application Form\n",
            "                                           Branch                                                     Joypurhat Loan Application Form\n",
            "                                      Account No.                                                    4476029692 Loan Application Form\n",
            "                               Amount Outstanding                                                        213706 Loan Application Form\n",
            "                                Monthly Repayment                                                         17491 Loan Application Form\n",
            "                                  Has Credit Card                                                           Yes Loan Application Form\n",
            "                              Issuing Institution                                                   Doyle Group Loan Application Form\n",
            "                                         Card No.                                           2183-7731-5204-7655 Loan Application Form\n",
            "                                            Limit                                                        194283 Loan Application Form\n",
            "                                      Outstanding                                                        109721 Loan Application Form\n"
          ]
        }
      ],
      "source": [
        "# --- Execution: Loan Application Form  ---\n",
        "# Collect all pages classified as Loan Application Form from the queue.\n",
        "loan_pages = [\n",
        "    (page_idx + 1, images[page_idx])\n",
        "    for page_idx, doc_type in queue\n",
        "    if \"loan application\" in doc_type.lower() and page_idx < len(images)\n",
        "]\n",
        "print(f\"Loan Application Form pages found: {[p for p, _ in loan_pages]}\")\n",
        "\n",
        "if loan_pages:\n",
        "    try:\n",
        "        loan_raw_md, loan_df = run_loan_form_extraction(loan_pages)\n",
        "        if not loan_df.empty:\n",
        "            results[\"Loan Application Form\"].append(loan_df)\n",
        "            print(f\"\\n{'='*60}\")\n",
        "            print(\"Loan Application Form — Merged DataFrame:\")\n",
        "            print(f\"{'='*60}\")\n",
        "            print(loan_df.to_string(index=False))\n",
        "        else:\n",
        "            print(\"No data extracted from Loan Application Form pages.\")\n",
        "    except torch.cuda.OutOfMemoryError:\n",
        "        print(\"\\n\" + \"!\"*60)\n",
        "        print(\"LOAN FORM EXTRACTION FAILED — CUDA Out of Memory.\")\n",
        "        print(\"All validation checks that depend on loan form data will show 'Missing'.\")\n",
        "        print(\"Fix: run 'clear_gpu()' first, or lower LOAN_FORM_MAX_PIXELS (e.g. 384*384).\")\n",
        "        print(\"!\"*60)\n",
        "        clear_gpu()\n",
        "else:\n",
        "    print(\"No Loan Application Form pages in the queue.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# STEP 3: VALIDATION OF DATA"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This is the elephant (quite literally) in the room.\n",
        "\n",
        "Could I have used ML models? Maybe. But all the data validation work perfectly with simple algorithms, so I didn't overdo. \n",
        "\n",
        "The real challenge is in the variety of data, techniques and validation strategy. For example, exact match makes sense for NID number cross-checking, but does it make sense for addresses, given how often people interchange 'Road number' and 'Road no.' (dare I mention rd no, road no, or just road)? In a sea of withdrawals and deposits, how do we identify a sneaky, one-time high influx to make the balance look good? Let us take a look, one validation type after one."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "There are four states after a validation is conducted.\n",
        "\n",
        "1. Green: Passed\n",
        "2. Yellow: Moderate concern\n",
        "3. Red: Grave concern, needs to be checked immediately\n",
        "4. Grey/Missing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Safety: ensure raw_outputs exists even if execution loop wasn't run in this session\n",
        "if 'raw_outputs' not in globals():\n",
        "    raw_outputs = {}\n",
        "if 'persona' not in globals():\n",
        "    persona = 'Service Holder'\n",
        "\n",
        "# ---------- helper functions ----------\n",
        "\n",
        "def fuzzy_ratio(s1, s2):\n",
        "    \"\"\"Fuzzy match ratio 0-100 using stdlib SequenceMatcher.\"\"\"\n",
        "    if not s1 or not s2:\n",
        "        return 0.0\n",
        "    return SequenceMatcher(None, str(s1).lower().strip(), str(s2).lower().strip()).ratio() * 100\n",
        "\n",
        "def _clean(v):\n",
        "    \"\"\"Return stripped string or None if empty/nan.\"\"\"\n",
        "    if v is None:\n",
        "        return None\n",
        "    v = str(v).strip()\n",
        "    return v if v and v.lower() not in (\"\", \"nan\", \"none\", \"n/a\", \"-\", \"(blank)\", \"(not found)\", \"tk. -\") else None\n",
        "\n",
        "def get_loan_field(*aliases):\n",
        "    \"\"\"Get a value from Loan Application Form by trying multiple substring aliases.\"\"\"\n",
        "    for df in results.get(\"Loan Application Form\", []):\n",
        "        if \"Field\" in df.columns and \"Value\" in df.columns:\n",
        "            for alias in aliases:\n",
        "                for _, row in df.iterrows():\n",
        "                    if alias.lower() in str(row[\"Field\"]).lower():\n",
        "                        val = _clean(row[\"Value\"])\n",
        "                        if val:\n",
        "                            return val\n",
        "    return None\n",
        "\n",
        "def get_doc_field(doc_type, *aliases):\n",
        "    \"\"\"Get a value from a GT document by trying multiple substring aliases.\"\"\"\n",
        "    for df in results.get(doc_type, []):\n",
        "        if \"Field\" in df.columns and \"Value\" in df.columns:\n",
        "            for alias in aliases:\n",
        "                for _, row in df.iterrows():\n",
        "                    if alias.lower() in str(row[\"Field\"]).lower():\n",
        "                        val = _clean(row[\"Value\"])\n",
        "                        if val:\n",
        "                            return val\n",
        "    return None\n",
        "\n",
        "def parse_num(val):\n",
        "    \"\"\"Parse numeric from string (strips commas, BDT, spaces).\"\"\"\n",
        "    if val is None:\n",
        "        return None\n",
        "    cleaned = re.sub(r'[^\\d.\\-]', '', str(val).replace(',', ''))\n",
        "    try:\n",
        "        return float(cleaned) if cleaned else None\n",
        "    except ValueError:\n",
        "        return None\n",
        "\n",
        "def has_data(doc_type):\n",
        "    \"\"\"True if results contains at least one non-empty DataFrame for doc_type.\"\"\"\n",
        "    return any(not df.empty for df in results.get(doc_type, []))\n",
        "\n",
        "def doc_required(doc_type):\n",
        "    \"\"\"True if doc_type is expected for the current persona.\"\"\"\n",
        "    try:\n",
        "        return doc_type in get_persona_categories(persona)\n",
        "    except Exception:\n",
        "        return True\n",
        "\n",
        "def get_bank_meta(key):\n",
        "    \"\"\"Parse AccName or AccNo from raw bank statement markdown headers.\"\"\"\n",
        "    for raw in raw_outputs.get(\"Bank Statement\", []):\n",
        "        m = re.search(rf'GT_Doc_Statement_{key}\\s*[:：]\\s*(.+)', raw, re.I)\n",
        "        if m:\n",
        "            return _clean(m.group(1))\n",
        "    return None\n",
        "\n",
        "def bank_total_credits():\n",
        "    \"\"\"Sum all Credit column values across Bank Statement DataFrames.\"\"\"\n",
        "    total, found = 0.0, False\n",
        "    for df in results.get(\"Bank Statement\", []):\n",
        "        if \"Credit\" in df.columns:\n",
        "            for v in df[\"Credit\"]:\n",
        "                n = parse_num(v)\n",
        "                if n and n > 0:\n",
        "                    total += n\n",
        "                    found = True\n",
        "    return total if found else None\n",
        "\n",
        "def bank_max_single_inflow():\n",
        "    \"\"\"Largest single Credit entry across Bank Statement DataFrames.\"\"\"\n",
        "    mx = 0.0\n",
        "    for df in results.get(\"Bank Statement\", []):\n",
        "        if \"Credit\" in df.columns:\n",
        "            for v in df[\"Credit\"]:\n",
        "                n = parse_num(v)\n",
        "                if n and n > mx:\n",
        "                    mx = n\n",
        "    return mx if mx > 0 else None\n",
        "\n",
        "# ---------- collect checks ----------\n",
        "checks = []\n",
        "\n",
        "def add(name, status, inspection=\"\"):\n",
        "    checks.append({\"Logical Check\": name, \"Status\": status, \"Inspection\": inspection})\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Validation type: Identity & statutory.** This block cross-checks identity and tax details between the loan application and the NID and TIN documents. It validates: **NID name**, **NID number**, **date of birth** (application vs NID), **TIN name**, and **TIN number** (application vs TIN certificate). \n",
        "\n",
        "Techniques: for names, fuzzy string matching (SequenceMatcher) with an 85% similarity threshold (Green/Yellow); for numeric fields (NID no., TIN no., DOB), digit-only normalization with `re.sub(r'\\D', '', ...)` then exact match. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ========================\n",
        "# 1. Identity & Statutory\n",
        "# ========================\n",
        "app_name = get_loan_field(\"applicant name\", \"full name\", \"personal info: full name\")\n",
        "\n",
        "# -- NID Name --\n",
        "nid_name = get_doc_field(\"NID\", \"nid_name\")\n",
        "if not has_data(\"NID\"):\n",
        "    if doc_required(\"NID\"):\n",
        "        add(\"NID Name Match\", \"Missing\", \"NID document not found in submission.\")\n",
        "elif app_name and nid_name:\n",
        "    r = fuzzy_ratio(app_name, nid_name)\n",
        "    if r >= 85:\n",
        "        add(\"NID Name Match\", \"Green\")\n",
        "    else:\n",
        "        add(\"NID Name Match\", \"Yellow\", f\"Fuzzy match {r:.0f}% (<85%). Cross-check name across documents.\")\n",
        "else:\n",
        "    add(\"NID Name Match\", \"Missing\", f\"{'Applicant Name' if not app_name else 'NID Name'} not extracted.\")\n",
        "\n",
        "# -- NID Number --\n",
        "app_nid = get_loan_field(\"nid no\", \"ids: nid\")\n",
        "doc_nid = get_doc_field(\"NID\", \"nid_no\")\n",
        "if not has_data(\"NID\"):\n",
        "    if doc_required(\"NID\"):\n",
        "        add(\"NID Number Match\", \"Missing\", \"NID document not found in submission.\")\n",
        "elif app_nid and doc_nid:\n",
        "    if re.sub(r'\\D', '', app_nid) == re.sub(r'\\D', '', doc_nid):\n",
        "        add(\"NID Number Match\", \"Green\")\n",
        "    else:\n",
        "        add(\"NID Number Match\", \"Red\", f\"Mismatch (App: {app_nid}, NID: {doc_nid}). Verify the physical NID card.\")\n",
        "else:\n",
        "    add(\"NID Number Match\", \"Missing\", f\"{'NID No. in app' if not app_nid else 'NID No. in doc'} not extracted.\")\n",
        "\n",
        "# -- Date of Birth --\n",
        "app_dob = get_loan_field(\"date of birth\", \"dob\", \"personal info: dob\")\n",
        "doc_dob = get_doc_field(\"NID\", \"nid_dob\")\n",
        "if not has_data(\"NID\"):\n",
        "    if doc_required(\"NID\"):\n",
        "        add(\"Date of Birth Match\", \"Missing\", \"NID document not found in submission.\")\n",
        "elif app_dob and doc_dob:\n",
        "    d1 = re.sub(r'\\D', '', app_dob)\n",
        "    d2 = re.sub(r'\\D', '', doc_dob)\n",
        "    if d1 == d2 or fuzzy_ratio(app_dob, doc_dob) > 90:\n",
        "        add(\"Date of Birth Match\", \"Green\")\n",
        "    else:\n",
        "        add(\"Date of Birth Match\", \"Red\", f\"DOB mismatch (App: {app_dob}, NID: {doc_dob}). Cross-reference with NID.\")\n",
        "else:\n",
        "    add(\"Date of Birth Match\", \"Missing\", f\"{'DOB in app' if not app_dob else 'DOB on NID'} not extracted.\")\n",
        "\n",
        "# -- TIN Name --\n",
        "tin_name = get_doc_field(\"TIN\", \"tin_name\")\n",
        "if not has_data(\"TIN\"):\n",
        "    if doc_required(\"TIN\"):\n",
        "        add(\"TIN Name Match\", \"Missing\", \"TIN document not found in submission.\")\n",
        "elif app_name and tin_name:\n",
        "    r = fuzzy_ratio(app_name, tin_name)\n",
        "    if r >= 85:\n",
        "        add(\"TIN Name Match\", \"Green\")\n",
        "    else:\n",
        "        add(\"TIN Name Match\", \"Yellow\", f\"Fuzzy match {r:.0f}% (<85%). Verify TIN certificate name aligns with NID.\")\n",
        "else:\n",
        "    add(\"TIN Name Match\", \"Missing\", f\"{'Applicant Name' if not app_name else 'TIN Name'} not extracted.\")\n",
        "\n",
        "# -- TIN Number --\n",
        "app_tin = get_loan_field(\"tin no\", \"ids: tin\")\n",
        "doc_tin = get_doc_field(\"TIN\", \"tin_number\", \"tin_no\", \"number\")\n",
        "if not has_data(\"TIN\"):\n",
        "    if doc_required(\"TIN\"):\n",
        "        add(\"TIN Number Match\", \"Missing\", \"TIN document not found in submission.\")\n",
        "elif app_tin and doc_tin:\n",
        "    if re.sub(r'\\D', '', app_tin) == re.sub(r'\\D', '', doc_tin):\n",
        "        add(\"TIN Number Match\", \"Green\")\n",
        "    else:\n",
        "        add(\"TIN Number Match\", \"Red\", f\"Mismatch (App: {app_tin}, Doc: {doc_tin}). Manually verify TIN via QR code.\")\n",
        "else:\n",
        "    add(\"TIN Number Match\", \"Missing\", f\"{'TIN No. in app' if not app_tin else 'TIN Number in doc'} not extracted.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Validation type: Address & utility.** This block verifies that the applicant’s stated residence aligns with the utility bill. It validates: (1) **Utility bill name match** — applicant name vs name on the bill (fuzzy match ≥85%), to ensure the bill is in the applicant’s name or a close variant; (2) **Present address match** — address on the application vs address on the utility bill (fuzzy match ≥80%), to allow for formatting differences (e.g. “Road no.” vs “Road number”). \n",
        "\n",
        "Techniques: fuzzy string comparison using SequenceMatcher; a slightly lower threshold (80%) for addresses to tolerate common formatting and abbreviation variations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# =============================\n",
        "# 2. Address & Utility\n",
        "# =============================\n",
        "util_name = get_doc_field(\"Utility Bill\", \"utility_name\")\n",
        "util_addr = get_doc_field(\"Utility Bill\", \"utility_address\")\n",
        "app_addr  = get_loan_field(\"present address\", \"contact: present\")\n",
        "\n",
        "if not has_data(\"Utility Bill\"):\n",
        "    if doc_required(\"Utility Bill\"):\n",
        "        add(\"Utility Bill Name Match\", \"Missing\", \"Utility Bill not found in submission.\")\n",
        "        add(\"Present Address Match\", \"Missing\", \"Utility Bill not found in submission.\")\n",
        "else:\n",
        "    if app_name and util_name:\n",
        "        r = fuzzy_ratio(app_name, util_name)\n",
        "        if r >= 85:\n",
        "            add(\"Utility Bill Name Match\", \"Green\")\n",
        "        else:\n",
        "            add(\"Utility Bill Name Match\", \"Yellow\", f\"Fuzzy match {r:.0f}% (<85%). Check if bill is under a relative's name; check for spelling errors.\")\n",
        "    else:\n",
        "        add(\"Utility Bill Name Match\", \"Missing\", f\"{'Applicant Name' if not app_name else 'Utility Name'} not extracted.\")\n",
        "\n",
        "    if app_addr and util_addr:\n",
        "        r = fuzzy_ratio(app_addr, util_addr)\n",
        "        if r >= 80:\n",
        "            add(\"Present Address Match\", \"Green\")\n",
        "        else:\n",
        "            add(\"Present Address Match\", \"Yellow\", f\"Address match {r:.0f}% (<80%). Manually review tokens (House No, Road, Area) for formatting variations.\")\n",
        "    else:\n",
        "        add(\"Present Address Match\", \"Missing\", f\"{'Present Address in app' if not app_addr else 'Address on Utility Bill'} not extracted.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Validation type: Employment (Service Holder).** This block runs only when the persona is Service Holder. It validates: (1) **Employer name on payslip** — application employer vs payslip employer (fuzzy match ≥85%); (2) **Employer name on Employee ID** — application employer vs organization name on the ID (fuzzy match ≥85%); (3) **Designation** — application designation vs Employee ID designation (fuzzy match ≥75%, lower threshold to allow abbreviations like “Sr. Exec” vs “Senior Executive”). \n",
        "\n",
        "Techniques: fuzzy string matching via SequenceMatcher for all three; Missing status if Pay Slip or Employee ID is absent or required fields are not extracted."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# =============================\n",
        "# 3. Employment (Service Holder)\n",
        "# =============================\n",
        "app_employer = get_loan_field(\"name of present employer\", \"employer name\", \"service holders: employer\")\n",
        "app_desig    = get_loan_field(\"designation\", \"service holders: designation\")\n",
        "\n",
        "if persona == \"Service Holder\":\n",
        "    # Payslip employer\n",
        "    ps_emp = get_doc_field(\"Pay Slip\", \"payslip_employer\")\n",
        "    if not has_data(\"Pay Slip\"):\n",
        "        if doc_required(\"Pay Slip\"):\n",
        "            add(\"Employer Name (Payslip)\", \"Missing\", \"Pay Slip not found in submission.\")\n",
        "    elif app_employer and ps_emp:\n",
        "        r = fuzzy_ratio(app_employer, ps_emp)\n",
        "        if r >= 85:\n",
        "            add(\"Employer Name (Payslip)\", \"Green\")\n",
        "        else:\n",
        "            add(\"Employer Name (Payslip)\", \"Yellow\", f\"Fuzzy match {r:.0f}% (<85%). Confirm payslip employer matches corporate records.\")\n",
        "    else:\n",
        "        add(\"Employer Name (Payslip)\", \"Missing\", f\"{'Employer in app' if not app_employer else 'Employer on Payslip'} not extracted.\")\n",
        "\n",
        "    # Employee ID employer\n",
        "    eid_org = get_doc_field(\"Employee ID\", \"empid_orgname\")\n",
        "    if not has_data(\"Employee ID\"):\n",
        "        if doc_required(\"Employee ID\"):\n",
        "            add(\"Employer Name (Employee ID)\", \"Missing\", \"Employee ID not found in submission.\")\n",
        "    elif app_employer and eid_org:\n",
        "        r = fuzzy_ratio(app_employer, eid_org)\n",
        "        if r >= 85:\n",
        "            add(\"Employer Name (Employee ID)\", \"Green\")\n",
        "        else:\n",
        "            add(\"Employer Name (Employee ID)\", \"Yellow\", f\"Fuzzy match {r:.0f}% (<85%). Confirm Employee ID org matches application.\")\n",
        "    else:\n",
        "        add(\"Employer Name (Employee ID)\", \"Missing\", f\"{'Employer in app' if not app_employer else 'Org on Employee ID'} not extracted.\")\n",
        "\n",
        "    # Designation\n",
        "    eid_desig = get_doc_field(\"Employee ID\", \"empid_designation\")\n",
        "    if has_data(\"Employee ID\") and app_desig and eid_desig:\n",
        "        r = fuzzy_ratio(app_desig, eid_desig)\n",
        "        if r >= 75:\n",
        "            add(\"Designation Check\", \"Green\")\n",
        "        else:\n",
        "            add(\"Designation Check\", \"Yellow\", f\"Match {r:.0f}%. Review job title abbreviations (e.g. 'Sr. Exec' vs 'Senior Executive').\")\n",
        "    elif has_data(\"Employee ID\"):\n",
        "        add(\"Designation Check\", \"Missing\", f\"{'Designation in app' if not app_desig else 'Designation on ID'} not extracted.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Validation type: Business & professional verification.** This block applies only to **Businessman** and **Self Employed** personas. For Businessman it validates: **Trade License** — organization name on the application vs the license (fuzzy match ≥90%, Red if below) and presence of license number. For Self Employed it validates: **Professional certificate** — applicant name vs name on the certificate (fuzzy match ≥85%). \n",
        "\n",
        "Techniques: same fuzzy string matching (SequenceMatcher) as identity checks, with a stricter 90% threshold for trade license name to reduce false positives on legal entity names."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ========================================\n",
        "# 4. Business & Professional Verification\n",
        "# ========================================\n",
        "if persona == \"Businessman\":\n",
        "    app_org = get_loan_field(\"organization name\", \"businessmen: organization\")\n",
        "    tl_org  = get_doc_field(\"Trade License\", \"tradelicense_orgname\")\n",
        "    tl_no   = get_doc_field(\"Trade License\", \"tradelicense_licenseno\")\n",
        "    if not has_data(\"Trade License\"):\n",
        "        if doc_required(\"Trade License\"):\n",
        "            add(\"Trade License Name Match\", \"Missing\", \"Trade License not found in submission.\")\n",
        "            add(\"Trade License Number\", \"Missing\", \"Trade License not found in submission.\")\n",
        "    else:\n",
        "        if app_org and tl_org:\n",
        "            r = fuzzy_ratio(app_org, tl_org)\n",
        "            if r >= 90:\n",
        "                add(\"Trade License Name Match\", \"Green\")\n",
        "            else:\n",
        "                add(\"Trade License Name Match\", \"Red\", f\"Fuzzy match {r:.0f}% (<90%). Manually verify license name and validity date.\")\n",
        "        else:\n",
        "            add(\"Trade License Name Match\", \"Missing\", f\"{'Org Name in app' if not app_org else 'Org on Trade License'} not extracted.\")\n",
        "        if tl_no:\n",
        "            add(\"Trade License Number\", \"Green\", \"Trade License number extracted. Manual verification of validity recommended.\")\n",
        "        else:\n",
        "            add(\"Trade License Number\", \"Missing\", \"License number not extracted from Trade License.\")\n",
        "\n",
        "if persona == \"Self Employed\":\n",
        "    cert_name = get_doc_field(\"Professional Certificate\", \"profcert_name\")\n",
        "    if not has_data(\"Professional Certificate\"):\n",
        "        if doc_required(\"Professional Certificate\"):\n",
        "            add(\"Prof. Certificate Name\", \"Missing\", \"Professional Certificate not found in submission.\")\n",
        "    elif app_name and cert_name:\n",
        "        r = fuzzy_ratio(app_name, cert_name)\n",
        "        if r >= 85:\n",
        "            add(\"Prof. Certificate Name\", \"Green\")\n",
        "        else:\n",
        "            add(\"Prof. Certificate Name\", \"Yellow\", f\"Fuzzy match {r:.0f}% (<85%). Check certificate name against NID.\")\n",
        "    else:\n",
        "        add(\"Prof. Certificate Name\", \"Missing\", f\"{'Applicant Name' if not app_name else 'Name on certificate'} not extracted.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Validation type: Financial & income consistency.** This block cross-checks banking and income data between the application and supporting documents. It validates: \n",
        "\n",
        "(1) **Bank account number**: Application vs statement (digit-normalized exact match); \n",
        "\n",
        "(2) **Salary** (Service Holder): Declared salary vs payslip net pay within a 10% deviation band; \n",
        "\n",
        "(3) **Income support**: Average statement credits vs declared total income (Green if avg ≥ declared, Yellow/Red for 70–100% or below); \n",
        "\n",
        "(4) **CIB liability**: Placeholders for manual review (not in the VLM pipeline; can be linked to a CIB database). "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ================================\n",
        "# 5. Financial & Income Consistency\n",
        "# ================================\n",
        "\n",
        "# Bank Account No\n",
        "app_bank_acc = get_loan_field(\"bank account no\", \"banking: account no\", \"banking: account\", \"account no\")\n",
        "doc_bank_acc = get_bank_meta(\"AccNo\")\n",
        "if not has_data(\"Bank Statement\"):\n",
        "    if doc_required(\"Bank Statement\"):\n",
        "        add(\"Bank Account No. Match\", \"Missing\", \"Bank Statement not found in submission.\")\n",
        "elif app_bank_acc and doc_bank_acc:\n",
        "    if re.sub(r'\\D', '', app_bank_acc) == re.sub(r'\\D', '', doc_bank_acc):\n",
        "        add(\"Bank Account No. Match\", \"Green\")\n",
        "    else:\n",
        "        add(\"Bank Account No. Match\", \"Red\", f\"Mismatch (App: {app_bank_acc}, Stmt: {doc_bank_acc}). Verify correct statement was submitted.\")\n",
        "else:\n",
        "    add(\"Bank Account No. Match\", \"Missing\", f\"{'Bank Acc in app' if not app_bank_acc else 'AccNo in statement'} not extracted.\")\n",
        "\n",
        "# Salary Validation (Service Holder)\n",
        "if persona == \"Service Holder\":\n",
        "    app_salary = parse_num(get_loan_field(\"salary\", \"monthly income: salary\"))\n",
        "    ps_netpay  = parse_num(get_doc_field(\"Pay Slip\", \"payslip_netpay\") or get_doc_field(\"Pay Slip\", \"net pay\"))\n",
        "    if has_data(\"Pay Slip\") and app_salary is not None and ps_netpay is not None and ps_netpay > 0:\n",
        "        dev = abs(app_salary - ps_netpay) / ps_netpay * 100\n",
        "        if dev <= 10:\n",
        "            add(\"Salary Validation\", \"Green\")\n",
        "        else:\n",
        "            add(\"Salary Validation\", \"Yellow\", f\"Declared salary ({app_salary:,.0f}) deviates {dev:.0f}% from Net Pay ({ps_netpay:,.0f}). Net Pay is the hard floor.\")\n",
        "    elif has_data(\"Pay Slip\"):\n",
        "        add(\"Salary Validation\", \"Missing\", f\"{'Salary in app' if app_salary is None else 'Net Pay on payslip'} not extracted.\")\n",
        "\n",
        "# Income Support (Statement vs Declared)\n",
        "app_income = parse_num(get_loan_field(\"total income\", \"total income (x)\"))\n",
        "stmt_credits = bank_total_credits()\n",
        "if has_data(\"Bank Statement\") and app_income and stmt_credits:\n",
        "    n_pages = max(len(results.get(\"Bank Statement\", [])), 1)\n",
        "    avg = stmt_credits / n_pages\n",
        "    if avg >= app_income:\n",
        "        add(\"Income Support (Statement)\", \"Green\")\n",
        "    elif avg >= app_income * 0.7:\n",
        "        add(\"Income Support (Statement)\", \"Yellow\", f\"Avg credits ({avg:,.0f}) somewhat below declared income ({app_income:,.0f}). Analyze for additional income streams.\")\n",
        "    else:\n",
        "        add(\"Income Support (Statement)\", \"Red\", f\"Avg credits ({avg:,.0f}) significantly below declared income ({app_income:,.0f}). Verify primary salary source.\")\n",
        "elif has_data(\"Bank Statement\"):\n",
        "    add(\"Income Support (Statement)\", \"Missing\", f\"{'Total Income in app' if not app_income else 'Credits in statement'} not available.\")\n",
        "elif doc_required(\"Bank Statement\"):\n",
        "    add(\"Income Support (Statement)\", \"Missing\", \"Bank Statement not found in submission.\")\n",
        "\n",
        "# Liability Check (CIB vs Declared) — CIB not extracted by VLM pipeline\n",
        "# Include for completeness; will be Missing unless CIB data is manually added\n",
        "add(\"Liability Check (CIB)\", \"Missing\", \"CIB report not part of VLM extraction pipeline. Manual review required.\")\n",
        "add(\"Liability Status (CIB)\", \"Missing\", \"CIB report not part of VLM extraction pipeline. Check if worst status is STD/UC.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Validation type: Behavioral & mathematical.** This block validates transaction behaviour and loan feasibility. It checks: \n",
        "\n",
        "(1) **Single inflow spike**: Whether any one credit entry exceeds twice the declared income (to flag potential one-off deposits that inflate the balance) \n",
        "\n",
        "(2) **Collateral sufficiency**: Whether total assets meet a 1.5× loan-amount ratio, with fallback inspection of liquid vs physical assets \n",
        "\n",
        "(3) **Loan serviceability**: Whether uncommitted income is at least twice the estimated EMI (to estimate loan serviceability)\n",
        "\n",
        "Note that these metrics are simply for demonstration purposes. The aim is to show that if a bank has other more professional/mathematically robust evaluation metrics, they can be implemented easily."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2026-02-16T02:34:57.432407Z",
          "iopub.status.busy": "2026-02-16T02:34:57.432204Z",
          "iopub.status.idle": "2026-02-16T02:34:57.502178Z",
          "shell.execute_reply": "2026-02-16T02:34:57.501463Z",
          "shell.execute_reply.started": "2026-02-16T02:34:57.432388Z"
        },
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "VALIDATION RESULTS\n",
            "================================================================================\n",
            "              Logical Check  Status                                                                                       Inspection\n",
            "             NID Name Match   Green                                                                                                 \n",
            "           NID Number Match     Red                     Mismatch (App: 54345495950, NID: 45345495959). Verify the physical NID card.\n",
            "        Date of Birth Match     Red                       DOB mismatch (App: 13-08-1978, NID: 1978-01-01). Cross-reference with NID.\n",
            "             TIN Name Match  Yellow                             Fuzzy match 24% (<85%). Verify TIN certificate name aligns with NID.\n",
            "           TIN Number Match     Red                Mismatch (App: 966146156867, Doc: 956146156867). Manually verify TIN via QR code.\n",
            "    Utility Bill Name Match   Green                                                                                                 \n",
            "      Present Address Match   Green                                                                                                 \n",
            "    Employer Name (Payslip)   Green                                                                                                 \n",
            "Employer Name (Employee ID) Missing                                                             Employee ID not found in submission.\n",
            "     Bank Account No. Match   Green                                                                                                 \n",
            "          Salary Validation   Green                                                                                                 \n",
            " Income Support (Statement)   Green                                                                                                 \n",
            "      Liability Check (CIB) Missing                          CIB report not part of VLM extraction pipeline. Manual review required.\n",
            "     Liability Status (CIB) Missing                 CIB report not part of VLM extraction pipeline. Check if worst status is STD/UC.\n",
            "        Single Inflow Spike  Yellow Single inflow (205,000) > 2x declared income (49,855). Check narrations for irregular transfers.\n",
            "     Collateral Sufficiency   Green                                                                                                 \n",
            "        Loan Serviceability     Red      Uncommitted income (-52,934) < 2x est. EMI (67,755). Deep-dive serviceability check needed.\n",
            "\n",
            "Summary: Green=8, Yellow=2, Red=4, Missing=3\n"
          ]
        }
      ],
      "source": [
        "# ==============================\n",
        "# 6. Behavioral & Mathematical\n",
        "# ==============================\n",
        "\n",
        "# Single Inflow Spike\n",
        "app_sal = parse_num(get_loan_field(\"salary\", \"monthly income: salary\")) or parse_num(get_loan_field(\"business income\", \"monthly income: business\"))\n",
        "max_inflow = bank_max_single_inflow()\n",
        "if has_data(\"Bank Statement\") and app_sal and max_inflow:\n",
        "    if max_inflow > 2 * app_sal:\n",
        "        add(\"Single Inflow Spike\", \"Yellow\", f\"Single inflow ({max_inflow:,.0f}) > 2x declared income ({app_sal:,.0f}). Check narrations for irregular transfers.\")\n",
        "    else:\n",
        "        add(\"Single Inflow Spike\", \"Green\")\n",
        "elif has_data(\"Bank Statement\"):\n",
        "    add(\"Single Inflow Spike\", \"Missing\", \"Salary/income or credit data not available for comparison.\")\n",
        "\n",
        "# Collateral Sufficiency\n",
        "loan_amt = parse_num(get_loan_field(\"amount sought\", \"loan info: amount\"))\n",
        "total_assets = parse_num(get_loan_field(\"total assets\", \"total assets (x)\"))\n",
        "if loan_amt and loan_amt > 0 and total_assets is not None:\n",
        "    ratio = total_assets / loan_amt\n",
        "    if ratio >= 1.5:\n",
        "        add(\"Collateral Sufficiency\", \"Green\")\n",
        "    else:\n",
        "        # Top 3 assets\n",
        "        asset_keys = [\"savings a/c\", \"current a/c\", \"fixed deposit\", \"land & building\", \"motor vehicles\", \"precious metals\"]\n",
        "        top = sorted([(k.title(), parse_num(get_loan_field(k)) or 0) for k in asset_keys], key=lambda x: -x[1])[:3]\n",
        "        top_str = \", \".join(f\"{n}: {v:,.0f}\" for n, v in top if v > 0) or \"None found\"\n",
        "        insp = f\"Asset/Loan ratio {ratio:.2f} (<1.5). Top assets: {top_str}.\"\n",
        "        # Liquid check\n",
        "        liquid = sum(parse_num(get_loan_field(k)) or 0 for k in [\"savings a/c\", \"current a/c\", \"fixed deposit\"])\n",
        "        if liquid / loan_amt >= 2:\n",
        "            insp += \" Liquid assets ratio >2x loan; collateral may not be needed.\"\n",
        "        # Physical check\n",
        "        physical = sum(parse_num(get_loan_field(k)) or 0 for k in [\"land & building\", \"motor vehicles\", \"precious metals\"])\n",
        "        if loan_amt > 0 and physical / loan_amt >= 1.5:\n",
        "            insp += \" Physical assets (Land/Vehicles/Metals) ratio >1.5x; recommend as collateral.\"\n",
        "        add(\"Collateral Sufficiency\", \"Red\", insp)\n",
        "elif loan_amt:\n",
        "    add(\"Collateral Sufficiency\", \"Missing\", \"Total Assets not found in Loan Application Form.\")\n",
        "\n",
        "# Uncommitted Income / Serviceability\n",
        "uncommitted = parse_num(get_loan_field(\"uncommitted income\", \"uncommitted income (x - y)\"))\n",
        "tenure = parse_num(get_loan_field(\"tenure\", \"loan info: tenure\"))\n",
        "if loan_amt and loan_amt > 0 and uncommitted is not None and tenure and tenure > 0:\n",
        "    emi_est = loan_amt / tenure  # simple estimate (real EMI includes interest)\n",
        "    if uncommitted >= 2 * emi_est:\n",
        "        add(\"Loan Serviceability\", \"Green\")\n",
        "    else:\n",
        "        add(\"Loan Serviceability\", \"Red\", f\"Uncommitted income ({uncommitted:,.0f}) < 2x est. EMI ({emi_est:,.0f}). Deep-dive serviceability check needed.\")\n",
        "elif uncommitted is None:\n",
        "    add(\"Loan Serviceability\", \"Missing\", \"Monthly uncommitted income not found in Loan Application Form.\")\n",
        "\n",
        "# ---------- output ----------\n",
        "validation_df = pd.DataFrame(checks)\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"VALIDATION RESULTS\")\n",
        "print(\"=\" * 80)\n",
        "print(validation_df.to_string(index=False))\n",
        "print(f\"\\nSummary: Green={len(validation_df[validation_df.Status=='Green'])}, \"\n",
        "      f\"Yellow={len(validation_df[validation_df.Status=='Yellow'])}, \"\n",
        "      f\"Red={len(validation_df[validation_df.Status=='Red'])}, \"\n",
        "      f\"Missing={len(validation_df[validation_df.Status=='Missing'])}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# STEP 4: OUTPUT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Output 1: Validation Table"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In this table, the validation results are aggregated and shown by name. The 'inspection' part lists additional insights/recommendations that apply to any particular check."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2026-02-16T02:34:57.503418Z",
          "iopub.status.busy": "2026-02-16T02:34:57.503130Z",
          "iopub.status.idle": "2026-02-16T02:34:57.522688Z",
          "shell.execute_reply": "2026-02-16T02:34:57.522072Z",
          "shell.execute_reply.started": "2026-02-16T02:34:57.503388Z"
        },
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Logical Check</th>\n",
              "      <th>Status</th>\n",
              "      <th>Inspection</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>NID Name Match</td>\n",
              "      <td>Green</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>NID Number Match</td>\n",
              "      <td>Red</td>\n",
              "      <td>Mismatch (App: 54345495950, NID: 45345495959)....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Date of Birth Match</td>\n",
              "      <td>Red</td>\n",
              "      <td>DOB mismatch (App: 13-08-1978, NID: 1978-01-01...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>TIN Name Match</td>\n",
              "      <td>Yellow</td>\n",
              "      <td>Fuzzy match 24% (&lt;85%). Verify TIN certificate...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>TIN Number Match</td>\n",
              "      <td>Red</td>\n",
              "      <td>Mismatch (App: 966146156867, Doc: 956146156867...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Utility Bill Name Match</td>\n",
              "      <td>Green</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Present Address Match</td>\n",
              "      <td>Green</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Employer Name (Payslip)</td>\n",
              "      <td>Green</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Employer Name (Employee ID)</td>\n",
              "      <td>Missing</td>\n",
              "      <td>Employee ID not found in submission.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Bank Account No. Match</td>\n",
              "      <td>Green</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>Salary Validation</td>\n",
              "      <td>Green</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>Income Support (Statement)</td>\n",
              "      <td>Green</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>Liability Check (CIB)</td>\n",
              "      <td>Missing</td>\n",
              "      <td>CIB report not part of VLM extraction pipeline...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>Liability Status (CIB)</td>\n",
              "      <td>Missing</td>\n",
              "      <td>CIB report not part of VLM extraction pipeline...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>Single Inflow Spike</td>\n",
              "      <td>Yellow</td>\n",
              "      <td>Single inflow (205,000) &gt; 2x declared income (...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>Collateral Sufficiency</td>\n",
              "      <td>Green</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>Loan Serviceability</td>\n",
              "      <td>Red</td>\n",
              "      <td>Uncommitted income (-52,934) &lt; 2x est. EMI (67...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                  Logical Check   Status  \\\n",
              "0                NID Name Match    Green   \n",
              "1              NID Number Match      Red   \n",
              "2           Date of Birth Match      Red   \n",
              "3                TIN Name Match   Yellow   \n",
              "4              TIN Number Match      Red   \n",
              "5       Utility Bill Name Match    Green   \n",
              "6         Present Address Match    Green   \n",
              "7       Employer Name (Payslip)    Green   \n",
              "8   Employer Name (Employee ID)  Missing   \n",
              "9        Bank Account No. Match    Green   \n",
              "10            Salary Validation    Green   \n",
              "11   Income Support (Statement)    Green   \n",
              "12        Liability Check (CIB)  Missing   \n",
              "13       Liability Status (CIB)  Missing   \n",
              "14          Single Inflow Spike   Yellow   \n",
              "15       Collateral Sufficiency    Green   \n",
              "16          Loan Serviceability      Red   \n",
              "\n",
              "                                           Inspection  \n",
              "0                                                      \n",
              "1   Mismatch (App: 54345495950, NID: 45345495959)....  \n",
              "2   DOB mismatch (App: 13-08-1978, NID: 1978-01-01...  \n",
              "3   Fuzzy match 24% (<85%). Verify TIN certificate...  \n",
              "4   Mismatch (App: 966146156867, Doc: 956146156867...  \n",
              "5                                                      \n",
              "6                                                      \n",
              "7                                                      \n",
              "8                Employee ID not found in submission.  \n",
              "9                                                      \n",
              "10                                                     \n",
              "11                                                     \n",
              "12  CIB report not part of VLM extraction pipeline...  \n",
              "13  CIB report not part of VLM extraction pipeline...  \n",
              "14  Single inflow (205,000) > 2x declared income (...  \n",
              "15                                                     \n",
              "16  Uncommitted income (-52,934) < 2x est. EMI (67...  "
            ]
          },
          "execution_count": 55,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "validation_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We use the same Qwen model (in text-only mode) to write a short executive summary of the validation results. The summary focuses on Red and Yellow issues. The output is a paragraph suitable for a credit committee or audit memo, so you get the most important insights at a glance.\n",
        "\n",
        "The prompt can be fine-tuned according to the banker's preference. For example, some may prefer more concise outputs in bullet-point separations.\n",
        "\n",
        "I checked the validations manually. I had injected some mismatches and those were detected perfectly. For example, I messed up the numbers on the NID intentionally, and the model was able to flag it.\n",
        "\n",
        "However, the TIN validation yielded a *false negative*, which is I have not modeled this tool as 'decisive'. The ultimate decision lies in the hands of a professional. Even if a banker has to confirm a false negative, it is a net win because a banker has to go through only 3-4 flagged mismatch cases."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Output 2: LLM-Based Summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2026-02-16T02:42:19.953261Z",
          "iopub.status.busy": "2026-02-16T02:42:19.952734Z",
          "iopub.status.idle": "2026-02-16T02:42:36.088469Z",
          "shell.execute_reply": "2026-02-16T02:42:36.087718Z",
          "shell.execute_reply.started": "2026-02-16T02:42:19.953234Z"
        },
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating LLM validation summary...\n",
            "\n",
            "================================================================================\n",
            "EXECUTIVE SUMMARY\n",
            "================================================================================\n",
            "The application contains critical issues that need immediate attention. The NID number and date of birth do not match, requiring verification against the physical card. Additionally, there is a discrepancy between the TIN number provided and the one on the document, necessitating manual verification through a QR code. The loan serviceability analysis indicates uncommitted income below twice the estimated EMI, warranting a thorough serviceability check. There are also concerns regarding a single inflow spike exceeding two times the declared income, which should be investigated further through narrative explanations. While the green validations have passed, the missing employer name (Employee ID) and the absence of the CIB report necessitate manual follow-up to ensure compliance and completeness.\n"
          ]
        }
      ],
      "source": [
        "def build_validation_summary(vdf):\n",
        "\n",
        "    priority_order = [\"Red\", \"Yellow\", \"Green\", \"Missing\"]\n",
        "    lines = []\n",
        "    for status in priority_order:\n",
        "        subset = vdf[vdf[\"Status\"] == status]\n",
        "        if subset.empty:\n",
        "            continue\n",
        "        lines.append(f\"[{status.upper()}]\")\n",
        "        for _, row in subset.iterrows():\n",
        "            insp = row.get(\"Inspection\", \"\")\n",
        "            entry = f\"- {row['Logical Check']}\"\n",
        "            if insp:\n",
        "                entry += f\": {insp}\"\n",
        "            lines.append(entry)\n",
        "    findings = \"\\n\".join(lines)\n",
        "\n",
        "    counts = vdf[\"Status\"].value_counts().to_dict()\n",
        "    stats = \", \".join(f\"{k}: {v}\" for k, v in counts.items())\n",
        "\n",
        "    prompt = (\n",
        "        \"You are a senior credit analyst reviewing a loan application. \"\n",
        "        \"Below are automated validation findings grouped by severity \"\n",
        "        \"(Red = critical, Yellow = needs attention, Green = passed, Missing = data unavailable).\\n\\n\"\n",
        "        f\"Validation counts — {stats}\\n\\n\"\n",
        "        f\"{findings}\\n\\n\"\n",
        "        \"Write an executive summary under 100 words. \"\n",
        "        \"Address Red issues first with the most urgency, then briefly mention the issues flagged as 'missing'. \"\n",
        "        \"In the end, just list the issues under yellow.\"\n",
        "        \"Use a professional, concise tone suitable for a credit committee memo. \"\n",
        "        \"Trim any introductory/concluding fat.\"\n",
        "    )\n",
        "\n",
        "    messages = [{\"role\": \"user\", \"content\": [{\"type\": \"text\", \"text\": prompt}]}]\n",
        "    text = processor.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
        "    inputs = processor(text=[text], padding=True, return_tensors=\"pt\").to(model.device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        output_ids = model.generate(**inputs, max_new_tokens=400)\n",
        "    generated_ids = [out[len(ins):] for ins, out in zip(inputs.input_ids, output_ids)]\n",
        "    summary = processor.batch_decode(generated_ids, skip_special_tokens=True)[0].strip()\n",
        "\n",
        "    del inputs, output_ids, generated_ids\n",
        "    gc.collect()\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "    return summary\n",
        "\n",
        "# --- Run ---\n",
        "print(\"Generating LLM validation summary...\\n\")\n",
        "summary = build_validation_summary(validation_df)\n",
        "print(\"=\" * 80)\n",
        "print(\"EXECUTIVE SUMMARY\")\n",
        "print(\"=\" * 80)\n",
        "print(summary)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Conclusion and AI Credits"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In real life, many pain points exist in loan validation, and document-backed verification is only one of them.\n",
        "\n",
        "This project does not address issues such as voice-based data collection or document integrity issues. The scope has been kept simple for demonstrative purposes. The goal was to deliver the idea that a modular, flexible validation pipeline is highly achievable. If someone wants to add a new persona or validation logic, the entire code won't fall apart. Only a few additions in certain places will do the trick.\n",
        "\n",
        "Generative AI was consulted for these specific purposes:\n",
        "1. Using HTML to create mock loan documents and reproduce them for synthetic aliases.\n",
        "2. Troubleshooting code errors in general.\n",
        "3. Learning and utilizing libraries I newly learned about (e.g. Torch, Difflib).\n",
        "4. Optimizing code to fit everything in limited GPU VRAM.\n",
        "5. Generating talking code for long operations to find exact issue points."
      ]
    }
  ],
  "metadata": {
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "datasetId": 9499200,
          "sourceId": 14851241,
          "sourceType": "datasetVersion"
        },
        {
          "datasetId": 9500089,
          "sourceId": 14852570,
          "sourceType": "datasetVersion"
        }
      ],
      "dockerImageVersionId": 31260,
      "isGpuEnabled": true,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
